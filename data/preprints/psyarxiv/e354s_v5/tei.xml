<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">dynConfiR: An R package for sequential sampling models of decision confidence</title>
				<funder ref="#_yz2KcF9 #_2zUVZkU #_uMnCmKV">
					<orgName type="full">Deutsche Forschungsgemeinschaft</orgName>
				</funder>
				<funder ref="#_3Rs93gX #_tpMSGR5 #_kpEjMtA">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2025-10-27">27 October 2025</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Sebastian</forename><surname>Hellmann</surname></persName>
							<email>sebastian.hellmann@tum.de</email>
							<affiliation key="aff0">
								<orgName type="department">Chair of Behavioral Research Methods</orgName>
								<orgName type="institution">TUM School of Management</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Philosophical-pedagogical Faculty</orgName>
								<orgName type="institution">Catholic University of Eichstätt-Ingolstadt</orgName>
								<address>
									<settlement>Eichstätt</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Michael</forename><surname>Zehetleitner</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Philosophical-pedagogical Faculty</orgName>
								<orgName type="institution">Catholic University of Eichstätt-Ingolstadt</orgName>
								<address>
									<settlement>Eichstätt</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Manuel</forename><surname>Rausch</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Philosophical-pedagogical Faculty</orgName>
								<orgName type="institution">Catholic University of Eichstätt-Ingolstadt</orgName>
								<address>
									<settlement>Eichstätt</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Faculty of Society and Economics</orgName>
								<orgName type="institution">Rhine-Waal University of Applied Sciences</orgName>
								<address>
									<settlement>Cleves</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">University of Klagenfurt</orgName>
								<address>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution" key="instit1">Unreviewed</orgName>
								<orgName type="institution" key="instit2">TUM School of Management</orgName>
								<address>
									<addrLine>Arcisstraße 21</addrLine>
									<postCode>80333</postCode>
									<settlement>München</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">dynConfiR: An R package for sequential sampling models of decision confidence</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2025-10-27">27 October 2025</date>
						</imprint>
					</monogr>
					<idno type="MD5">8661B4E7BF19365E0A1ACECE6028B347</idno>
					<note type="submission">Preprint</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-11-18T15:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=true, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>R package</term>
					<term>cognitive modeling</term>
					<term>confidence</term>
					<term>decision making</term>
					<term>drift diffusion models</term>
					<term>sequential sampling models DYNCONFIR</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The modeling of response times using sequential sampling models has a long history. Because choices, confidence judgments, and reaction times are closely linked in perceptual decisions, it seems only natural to simultaneously model these three outcome variables of a decision. In the package dynConfiR, we implemented various sequential sampling models of choice, response time, and decision confidence in R.</p><p>This paper gives an overview of the package, which provides probability density functions as well as high-level functions for fitting parameters to empirical data, prediction of reaction time and response distributions and simulation of artificial data sets. We describe the mathematical specification of the implemented models and give a detailed description of the implemented likelihood functions. In addition, we outline the workflow for applying the model to empirical data step-by-step: data preprocessing, model fitting, model prediction, quantitative model comparison, and visual assessment of model predictions.</p><p>Finally, we present results from a parameter and model recovery analyses and assess the precision in calculating probability densities, illustrating the reliability of the implemented computations. Offering intuitive usability and high flexibility, the package is targeted at researchers in the fields of decision-making and confidence and does not require expert-level programming skills.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Recently, confidence has gained increasing research interest in the field of cognitive computational modeling (e.g., <ref type="bibr" target="#b0">Adler &amp; Ma, 2018;</ref><ref type="bibr" target="#b1">Aitchison et al., 2015;</ref><ref type="bibr" target="#b11">Desender et al., 2021;</ref><ref type="bibr" target="#b20">Hellmann et al., 2023</ref><ref type="bibr" target="#b21">Hellmann et al., , 2024;;</ref><ref type="bibr" target="#b24">Kiani et al., 2014;</ref><ref type="bibr">Maniscalco &amp; Lau, 2016;</ref><ref type="bibr">Maniscalco et al., 2016;</ref><ref type="bibr" target="#b38">Moran et al., 2015;</ref><ref type="bibr" target="#b48">Pleskac &amp; Busemeyer, 2010;</ref><ref type="bibr" target="#b55">Ratcliff &amp; Starns, 2009</ref><ref type="bibr" target="#b25">, 2013;</ref><ref type="bibr" target="#b59">Rausch et al., 2018;</ref><ref type="bibr" target="#b87">Zawadzka et al., 2017)</ref>. Many experimental tasks and everyday decisions include uncertainty, so the decision-maker can not be entirely sure whether their decision was correct. The resulting degree of belief in the correctness of one's decision is referred to as confidence <ref type="bibr" target="#b49">(Pouget et al., 2016)</ref>. Because confidence is also relevant in everyday behavior and communication, for example when driving in a foggy environment or making difficult medical diagnoses, it is essential to understand how confidence arises from the decision process.</p><p>Many models of confidence are based on traditional signal detection theory (SDT, <ref type="bibr" target="#b17">Green &amp; Swets, 1966)</ref>. We refer to these models as static models as they do not explain the single trial dynamics of a decision but assume that the decision is made by comparing a single random variable against a criterion.</p><p>Traditional SDT models have been extended to account for confidence judgments, for example by introducing more criteria, additional information gain, or noise in the confidence judgment <ref type="bibr" target="#b0">(Adler &amp; Ma, 2018;</ref><ref type="bibr" target="#b33">Mamassian &amp; de Gardelle, 2022;</ref><ref type="bibr" target="#b59">Rausch et al., 2018</ref><ref type="bibr" target="#b60">Rausch et al., , 2023;;</ref><ref type="bibr" target="#b69">Shekhar &amp; Rahnev, 2021</ref><ref type="bibr">, 2024)</ref>. Static confidence models have proven successful in accounting for the relationship between task difficulty and confidence and have been useful for explaining discrepancies between confidence judgments and actual accuracy. Although response times may be incorporated into these models to account for the dynamical properties of the generation of evidence on which the decisions are based, e.g. by scaling both the magnitude and noise with the response time, they do not provide an explanation for how response times are generated as a dependent variable. For this reason static models may be applied to interrogation tasks <ref type="bibr" target="#b5">(Bogacz et al., 2006)</ref>, in which the experimenter externally controls how long evidence may be accumulated, but cannot account for the empirical patterns like the negative relationship between discriminability and response times that are commonly observed in free response tasks, in which subjects themselves determine when to make a decision. In addition, confidence is also closely related to decision time in many free response tasks <ref type="bibr" target="#b21">(Hellmann et al., 2024;</ref><ref type="bibr" target="#b24">Kiani et al., 2014;</ref><ref type="bibr" target="#b50">Rahnev et al., 2020;</ref><ref type="bibr" target="#b80">Vickers et al., 1985)</ref>. In contrast to static models, dynamical models explain the generation of response time distributions and may thus provide insight into the causal relationship between task difficulty, decision time, and confidence. Dynamical models of decision-making assume a sequential sampling process, that is, evidence is sampled from a noisy distribution repeatedly over time, and an internal decision variable is updated until a particular stopping rule is met and the decision is triggered <ref type="bibr" target="#b54">(Ratcliff &amp; Smith, 2004)</ref>. It should be noted that most sequential sampling models of decision making are based on signal detection principles and thus the term dynamical signal detection theory is occasionally used for random walk models <ref type="bibr" target="#b48">(Pleskac &amp; Busemeyer, 2010;</ref><ref type="bibr" target="#b72">Smith, 2000)</ref>.</p><p>A prominent example of a computational model in the field of decision-making research is the drift diffusion model (DDM) which was originally used to explain response time distributions in memory retrieval tasks <ref type="bibr" target="#b51">(Ratcliff, 1978)</ref>. Since it was initially formulated, it was extended by including additional parameters and applied in various experimental tasks <ref type="bibr" target="#b54">(Ratcliff &amp; Smith, 2004)</ref>. However, the DDM, in its original conception, does not account for confidence judgments. In two previous studies, we compared different confidence models based on two important prototypes of dynamical models of decision-making, the DDM and the race of accumulators <ref type="bibr" target="#b20">(Hellmann et al., 2023</ref><ref type="bibr" target="#b21">(Hellmann et al., , 2024))</ref>. We demonstrated that fitting the joint distribution of choice, response time, and confidence is useful for testing computational models of decision making and is more desirable than fitting summary statistics of the data.</p><p>The presented package includes functions to fit response times and confidence judgments in binary choice tasks based on the following models: the drift diffusion confidence model <ref type="bibr">(DDConf, Hellmann et al., 2023;</ref><ref type="bibr" target="#b51">Ratcliff, 1978)</ref>, the two-stage dynamical signal detection model (2DSD, <ref type="bibr" target="#b48">Pleskac &amp; Busemeyer, 2010)</ref>, the dynamical weighted evidence and visibility model <ref type="bibr">(dynWEV, Hellmann et al., 2023)</ref>, the dynamical visibility, time, and evidence model <ref type="bibr">(dynaViTE, Hellmann et al., 2024)</ref>, several versions of race models <ref type="bibr" target="#b39">(Moreno-Bote, 2010)</ref>, and the multiple-threshold correlated log-normal race model <ref type="bibr">(MTLNR, Reynolds et al., 2020)</ref>. The models are explained in more detail in the next section.</p><p>Due to their mathematical complexity, dynamical models of decision-making and confidence are challenging to implement. By providing the dynConfiR package, we aim to remove the hurdle of implementing likelihood functions and fitting procedures to facilitate the application of confidence models for research questions in psychology and cognitive neuroscience.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Alternative software</head><p>Software already exists to analyze response time data for decision models, mainly in the context of the DDM. Some examples are the R packages rtdists <ref type="bibr" target="#b71">(Singmann et al., 2020)</ref>, which offers probability distribution and simulation functions for the seven-parameter DDM and the linear ballistic accumulator model <ref type="bibr" target="#b8">(Brown &amp; Heathcote, 2008)</ref>, and RWiener <ref type="bibr" target="#b84">(Wabersich &amp; Vandekerckhove, 2014b)</ref>, which provides an implementation of the four-parameter DDM with functions for parameter fitting. <ref type="bibr">Fast-dm (Andreas Voss &amp; Jochen Voss, 2007</ref>) is a stand-alone command line tool for fitting the seven-parameter DDM to empirical data. This tool also allows to fit the model with arbitrary parameters varying across different conditions.</p><p>The python toolbox HDDM allows for hierarchical parameter estimation of DDM parameters <ref type="bibr" target="#b86">(Wiecki et al., 2013)</ref>. Similarly, the EMC2 is an R package that allows for the Bayesian estimation of parameters in various evidence accumulation models to choice and response time data <ref type="bibr" target="#b74">(Stevenson et al., 2024)</ref>. These packages are immensely flexible when it comes to the specification of the hypothesized effect of experimental manipulations and other predictors on model parameters. In that sense, confidence judgments could be incorporated into the analysis as an additional predictor, e.g. for guiding learning <ref type="bibr" target="#b13">(Drugowitsch et al., 2019)</ref> or influence the decision-threshold in upcoming trials <ref type="bibr" target="#b10">(Desender et al., 2019)</ref>.</p><p>However, these tools do not allow scientists to easily include confidence judgments as an additional dependent variable in the computational models.</p><p>In addition, the wiener module for JAGS <ref type="bibr">(Wabersich &amp; Vandekerckhove, 2014a)</ref> and Stan allow researchers to easily incorporate the DDM in more complex probabilistic models (see e.g. <ref type="bibr" target="#b16">Fontanesi et al., 2019</ref>, for an application in reinforcement learning). Recently, the seven-parameter DDM was implemented in Stan <ref type="bibr" target="#b22">(Henrich et al., 2024)</ref>. Using JAGS or Stan, scientist could also build more complex models, to account for confidence data, however, this requires at least some knowledge in MCMC sampling and knowledge of either software tool. In addition, to include other models that are not based on the DDM like race models, researchers would have to write their own extension in the form of a likelihood function.</p><p>As a summary, there are a lot of alternatives when it comes to the models to the modeling of choices and response times. These alternatives are already very popular and provide a high degree of flexibility and some allow for the hierarchical estimation of model parameters, which is beneficial if only a limited number of trial are available for each subject.</p><p>For fitting confidence data, the statConfR package <ref type="bibr" target="#b61">(Rausch et al., 2025)</ref> allows for parameter fitting in the context of static confidence models and the computation of popular measures of metacognitive performance such as meta-d ′ <ref type="bibr" target="#b34">(Maniscalco &amp; Lau, 2012)</ref>. The ReMeta toolbox is a Python library which facilitates the estimation of parameters with a high degree of flexibility in specifying the data generating process <ref type="bibr" target="#b18">(Guggenmos, 2022)</ref>. Finally, <ref type="bibr" target="#b33">Mamassian and de Gardelle (2022)</ref> provided a Matlab toolbox to fit confidence judgments in the so-called confidence forced-choice paradigm. However, these software packages are based on signal-detection models and cannot account for response times.</p><p>Table <ref type="table">1</ref> summarizes and compares available software to the dynConfiR package. Only very few software tools currently exist that implement sequential sampling models of confidence. The DMC software includes an implementation of the multiple-threshold linear ballistic accumulator model and the MTLNR <ref type="bibr" target="#b19">(Heathcote et al., 2019;</ref><ref type="bibr" target="#b64">Reynolds et al., 2020)</ref>. Unfortunately at the time of writing, the DMC software is no more actively maintained and comprehensive documentation for the application of these models is not available. Instead, the authors of DMC are planning to extend the EMC2 software to include confidence models in a future release (A. <ref type="bibr">Heathcote, personal communication, September 18, 2025)</ref>. dynConfiR provides implementations of the joint distribution of choice, response time, and confidence judgment for several sequential sampling models of decision confidence together with wrapper functions to compute the likelihood for a whole data set and a given set of parameters. This enables advanced users to define custom likelihood functions tailored to their specific experiments. Particularly, researchers can implement their own mapping between stimulus properties and drift rates in two-alternative force-choice tasks, and incorporate attentional discounts when eye-tracking data are available <ref type="bibr" target="#b26">(Krajbich et al., 2010)</ref>.</p><p>In addition, the package includes functions for maximum-likelihood parameter estimation and for predicting or simulating distributions, which facilitates the use by less-advanced users, who want to focus on the application of the models to their data. Functions are written to provide an intuitive and straightforward way to implement the whole workflow of model fitting and comparison with only a few lines of code while still providing possibilities for customization, for example, fixing parameters that should not be fitted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1</head><p>Comparison of features of the dynConfiR to other existing software.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dependent variables</head><p>User-accessible functions</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Software</head><p>Programming language</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Response times</head><p>Confidence judgments</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Density functions</head><p>Fitting functions</p><formula xml:id="formula_0">Statistical paradigm rtdists R ✓ ✗ ✓ ✗ frequentist RWiener R ✓ ✗ ✓ ✓ frequentist Fast-dm stand-alone command line tool ✓ ✗ ✗ ✓ frequentist HDDM Python ✓ ✗ ✓ ✓ Bayesian EMC2 R ✓ ✗ ✗ ✓ Bayesian wiener module JAGS ✓ ✗ - - Bayesian lpdf_wiener Stan ✓ ✗ - - Bayesian statConfR R ✗ ✓ ✗ ✓ frequentist ReMeta Python ✗ ✓ ✗ ✓ frequentist cfc Matlab ✗ ✓ ✗ ✓ frequentist dynConfiR R ✓ ✓ ✓ ✓ frequentist</formula><p>Note. ✓: available; ✗: not available; -: not applicable</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Scope and limitations of the package</head><p>Although the dynConfiR package implements various computational models covering a broad range of concepts (e.g. models with post-decisional accumulation time, race models and drift diffusion models) and the fitting procedure is user-friendly, there are some limitations concerning both the scope and the usability of the package we will describe below.</p><p>First, we restricted the implementation of models to confidence models for which the likelihood of the joint distribution of choices, response times, and confidence judgments is mathematically tractable.</p><p>This means that the models do not capture several aspects and variations of the models discussed in the literature, e.g., collapsing boundaries and leakage. All models assume time-constant boundaries as well as stationary drift rates, which are independent of the current state of the process. In addition, the race models do not allow for inhibition. Time-collapsing boundaries are discussed in the literature to implement time-costs in the diffusion process, and leakage and inhibition are referred to as neurally plausible mechanisms of accumulation processes <ref type="bibr" target="#b75">(Tajima et al., 2016;</ref><ref type="bibr" target="#b78">Usher &amp; McClelland, 2001)</ref>. In addition, several dynamic confidence models like RTCON and RTCON2 <ref type="bibr" target="#b55">(Ratcliff &amp; Starns, 2009</ref><ref type="bibr" target="#b25">, 2013)</ref> and the bounded accumulation model by <ref type="bibr" target="#b24">Kiani et al. (2014)</ref> are not implemented in the package. As new computational models of confidence judgments keep being proposed, we plan to extend the range of models in the future with other models. In addition, we encourage contributions to the package by other researchers (see the GitHub page of the package).</p><p>Second, despite some of the models assuming post-decisional evidence accumulation, there is currently no model implemented that also accounts for confidence response times in paradigms with subsequent confidence reports. In such situations, one has to rely on the observed confidence response times to inform the post-decisional accumulation period (see <ref type="bibr" target="#b21">Hellmann et al., 2024)</ref>. There are some proposed models that do account for confidence response times, which are not yet implemented in dynConfiR <ref type="bibr" target="#b23">(Herregods et al., 2023;</ref><ref type="bibr" target="#b38">Moran et al., 2015)</ref>. Importantly, the models assuming post-decisional evidence accumulation accounted for response times and confidence judgments in paradigms with simultaneous choice and confidence reports and even outperformed the alternative models that did not include post-decisional accumulation <ref type="bibr" target="#b20">(Hellmann et al., 2023)</ref>.</p><p>Third, although we restrict the package to include only models with a feasible likelihood, the parameter fitting procedure requires a lot of computation time. Because the implemented maximum likelihood procedure for parameter fitting requires the computation of the joint distribution on a trial-level for each iteration, even with the effective finite sum approximations of the response time density in the diffusion-based models, the computational effort is considerable (see also the sections Model recovery analysis and Parameter recovery analysis, where we report the computation times for the likelihood evaluation and parameter fitting).</p><p>Finally, there are some conceptual limitations that come with the maximum likelihood estimation technique used for parameter fitting. Unlike in Bayesian estimation methods, the estimated parameters are only point estimates and there is no measure for the uncertainty of the estimation. There is no implemented method to report confidence intervals for the parameters because the dependency among each other (e.g., confidence thresholds need to be ordered) makes the standard procedures for computing confidence intervals difficult. The information criteria used for assessing the goodness-of-fit of the models are also based on the maximum likelihood estimation and do not account for the functional complexity of the models <ref type="bibr" target="#b41">(Myung, 2000)</ref>. However, the good model identification presented in this article (see Model recovery analysis) indicates that using BIC for model comparison has generally a low level of mis-identifications when the models are fitted to empirical data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Structure of the present paper</head><p>In the present paper, we will first present the confidence models that are included in the package, explaining all parameters and giving mathematical definitions. The second section provides details about the functionalities of the package. Based on the implemented functionalities, we propose workflows for different use cases and show possibilities for individual settings in the analyses. In addition, we showcase the suggested workflow for model comparison using an empirical data set. The sections Parameter recovery analysis, Precision analysis, and Model recovery analysis contain results from simulation studies examining the performance of the package. All analyses scripts and data sets used in this paper are available at <ref type="url" target="https://github.com/SeHellmann/dynConfiR_Paper">https://github.com/SeHellmann/dynConfiR_Paper</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sequential sampling confidence models</head><p>In this section, we describe the sequential sampling models included in dynConfiR in detail. Most dynamic models of decision-making share the idea that a decision is not based on a single sample, as in SDT. In contrast, sequential sampling models describe decisions as processes in which evidence is repeatedly sampled and accumulated over time <ref type="bibr" target="#b54">(Ratcliff &amp; Smith, 2004)</ref>. Starting from a discrete-time perspective and normally distributed samples, reducing the time step size leads to a continuous Wiener process describing the accumulation of evidence. The use of Wiener processes is also in accordance with the idea that the internal evidence signal is represented by a sufficiently large set of neurons. The Wiener process may be interpreted as the stochastic process equivalent to the Gaussian distribution. This is because the functional invariance principle states that accordingly scaled partial sum processes, which formalize the idea of sequentially sampling and integrating evidence mathematically, converge to a Wiener process in the limit of small time steps <ref type="bibr" target="#b25">(Klenke, 2013)</ref>. However, there are dynamical models of decision-making that explicitly use other processes, like the Poisson counter model <ref type="bibr" target="#b27">(LaBerge, 1994)</ref> or the leaky competing accumulator model <ref type="bibr" target="#b78">(Usher &amp; McClelland, 2001)</ref>. The accumulation of evidence continues until enough information in favor of one alternative is available, formalized by a stopping criterion. When the stopping criterion is met, a choice is triggered for the alternative favored by the accumulated evidence.</p><p>All models included in dynConfiR assume that stopping criteria take the form of time-constant absorbing boundaries. Alternative models that suggest collapsing boundaries, which approach the starting point over time <ref type="bibr" target="#b14">(Drugowitsch et al., 2012;</ref><ref type="bibr" target="#b37">Milosavljevic et al., 2010;</ref><ref type="bibr" target="#b75">Tajima et al., 2016)</ref>, are not included in the package. Sequential sampling models of decision-making provide explanations for the correlation between discriminability and reaction time and the speed-accuracy trade-off <ref type="bibr" target="#b30">(Lerche &amp; Voss, 2019;</ref><ref type="bibr" target="#b53">Ratcliff &amp; Rouder, 1998)</ref>. The dynConfiR package features two classes of dynamical confidence models. The first class of models is based on the DDM, which assumes a single accumulation process representing evidence in favor of one choice alternative over the other. The second class of models is race models, which assumes multiple accumulation processes, each representing one choice alternative. Among the race models, the MTLNR is treated in an independent section because it does not use Wiener processes but simplifies the accumulation process to a ballistic accumulation without noise <ref type="bibr" target="#b7">(Brown &amp; Heathcote, 2005)</ref>. In the sections that follow, we first describe the most general model of the first class, the dynamical visibility, time, and evidence model (dynaViTE), and how the other models of this class, DDConf, 2DSD, and dynWEV, are special cases of dynaViTE. We will then describe the second class of models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Drift diffusion-based confidence models</head><p>We first present the decision mechanism that is the basis for the first class of models. In the DDM, the decision process is described as a Wiener process, which is bounded by two time-constant thresholds 0 and a. The process X starts at the starting point X(0). The relative starting position between the two thresholds, i.e. X(0)/a, follows a uniform distribution around the parameter z with range s z , formally</p><formula xml:id="formula_1">X(0)/a ∼ Unif[z -s z /2, z + s z /2].</formula><p>The process then evolves with a drift of µ, which is normally distributed around ν with standard deviation s ν . The diffusion constant is denoted as s. When the process first hits either the lower or the upper threshold, a decision is triggered. Decision time is thus defined as</p><formula xml:id="formula_2">T Dec = min{t|X(t) ∈ {0, a}}.</formula><p>The choice response R is -1 if the lower threshold was hit, i.e., if X(T Dec ) = 0, and it is +1, otherwise.</p><p>Correspondingly, in discrimination tasks, the sign of the mean drift rate reflects the true stimulus identity, S = sig(ν), while its magnitude is determined by experimental manipulations in task difficulty (see section</p><p>Fitting confidence models to experimental data).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dynamical visibility, time, end evidence model (dynaViTE)</head><p>The dynaViTE model assumes that the decision process X continues after it reaches one of the two thresholds. This accumulation continues for a fixed period of time, which is represented by the parameter τ . In addition, dynaViTE postulates a second process evolving in parallel to the decision process. The second process is denoted as visibility process V and is again a Wiener process, which always starts as 0. Its drift rate is subject to noise similar to the drift rate in the decision process. More precisely, the visibility drift is normally distributed with mean visibility drift µ V and standard deviation σ V . The diffusion constant of the visibility process is represented by the parameter s V . Importantly, only one parameter in dynaViTE can be fixed to scale the other parameters without affecting model predictions.</p><p>That is, if the diffusion constant of the decision process s is fixed, then s V cannot be fixed as well without restricting the model. The psychological interpretation of the two processes is as follows: While the decision process accumulates evidence about the identity of the stimulus, i.e., whether it belongs to the class representing the upper or lower threshold, respectively, the visibility process accrues evidence about stimulus features that are indicative of task difficulty but not informative for the stimulus identity. In visual discrimination tasks -for which dynaViTE was originally proposed -visibility may be task-irrelevant stimulus features like brightness, shape, presentation time, or contour.</p><p>Confidence is then a function of the accumulated decision evidence (X(T Dec + τ ) -az), visibility evidence (V (T Dec + τ )), and accumulation time (T Dec + τ ). After the post-decisional accumulation period, accumulated evidence in the two processes is combined in a weighted sum and divided by a power of accumulation time to form an internal confidence variable</p><formula xml:id="formula_3">c dynaV iT E = wR(X(T Dec + τ ) -az) + (1 -w)V (T Dec + τ ) (T Dec + τ ) λ , (<label>1</label></formula><formula xml:id="formula_4">)</formula><p>in which the parameter w controls the weight on decision evidence compared to visibility evidence, and λ controls the penalty of accumulation time on confidence. The factor R in the numerator of eqn (1) leads to a positive scaling of choice congruent evidence in the case when the choice is R = -1 (i.e., the lower threshold was hit first) because more negative values of X(T Dec -τ ) -az support a 'lower' decision and thus should lead to higher confidence. For perceptual decision tasks without independent manipulation of discriminability and visibility, the mean drift rate of the visibility process was previously set to the absolute mean drift of the decision process, µ V = |ν| <ref type="bibr" target="#b20">(Hellmann et al., 2023</ref><ref type="bibr" target="#b21">(Hellmann et al., , 2024))</ref>. Setting the visibility drift rate to the absolute value of the decision drift rate follows the assumption that stimuli, which are easier to discriminate, are also perceived as more reliable, independent of their category. For example, when manipulating the stimulus-onset-asynchrony in a masked discrimination task, the time the stimulus was present on the screen may be perceived independently of the evidence about the stimulus category.</p><p>Because stimuli that are presented longer are easier to discriminate, a longer stimulus duration increases confidence irrespective of the choice. A detailed derivation of the confidence variable in dynaViTE and justification of the form of time penalization is provided by <ref type="bibr" target="#b21">Hellmann et al. (2024)</ref>. DynaViTE includes simpler confidence models that were previously studied in the literature. The following special cases are implemented with their own name in dynConfiR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dynamical weighted evidence and visibility model (dynWEV)</head><p>The dynWEV model is a dynamical version of a previously proposed static model of confidence, the weighted evidence and visibility model <ref type="bibr" target="#b59">(Rausch et al., 2018)</ref>. DynWEV is equivalent to the dynaViTE model without considering the accumulation time penalization in the confidence measure, i.e., λ = 0, such that</p><formula xml:id="formula_5">c dynW EV = wR(X(T Dec + τ ) -az) + (1 -w)V (T Dec + τ ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Two-stage dynamic signal detection theory (2DSD)</head><p>The 2DSD model does not assume parallel accumulation of visibility evidence and also has no penalization for accumulation time. In 2DSD, confidence only depends on whether the evidence accumulated in the post-decisional accumulation period supports or contradicts the choice <ref type="bibr" target="#b48">(Pleskac &amp; Busemeyer, 2010)</ref>. 2DSD is a special case of dynaViTE for λ = 0 and w = 1. Setting w = 1 leads to a zero weight on the visibility process, which is thus completely ignored in the likelihood. In addition, λ = 0 implies that the denominator in eqn (1) is always 1, and accumulation time has no direct influence on confidence. The confidence variable has the form c 2DSD = R(X(T Dec + τ ) -az).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Drift diffusion confidence model (DDConf)</head><p>The drift diffusion confidence model is based on the the formula for optimal confidence in the DDM when drift rates are uniformly distributed (Moreno-Bote, 2010), which indicates that confidence is a monotonically decreasing function of decision time. More precisely, the confidence variable is defined as</p><formula xml:id="formula_6">c DDM = 1 √ T Dec .</formula><p>DDConf is mathematically equivalent to the dynaViTE model with w = 1, τ = 0, and λ = 0.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Race Models using Wiener processes</head><p>The drift diffusion model that serves as the basis for the previously described models assumes only one accumulation process representing relative evidence for competing decision alternatives. In contrast, race models include one accumulation process for each decision alternative. Each of the processes accrues information in favor of the corresponding decision alternative. These models are theoretically applicable to decision tasks with an arbitrary number of alternatives. In the binary setting, the two accumulators may be described as a two-dimensional Gaussian process (X 1 , X 2 ) starting at (0, 0), with constant drift (µ 1 , µ 2 ) and covariance matrix Σ =</p><formula xml:id="formula_7">σ 2 1 σ1σ2ρ σ1σ2ρ σ 2 2</formula><p>. Similar to the diffusion constant, σ 1 and σ 2 may be set to 1 as scaling factors. Each component of the process is bound from above by a time constant threshold A and B, respectively. A decision is triggered as soon as one of the accumulators hits its threshold. Decision time is thus defined by</p><formula xml:id="formula_8">T Dec = min {t | X 1 (t) &gt; A ∨ X 2 (t) &gt; B} and the response R is 1, if X 1 (T Dec ) &gt; A and 2, if X 2 (T Dec ) &gt; B.</formula><p>In dynConfiR, the correlation parameter ρ is restricted to either ρ = 0, which results in the model denoted as the independent race model (IRM), or ρ = -.5, for which the respective model is denoted as the partially correlated race model (PCRM). The reason for restricting ρ to either 0 or -.5 is that for these values, there are closed-form solutions for the first passage time densities (Moreno-Bote, 2010).</p><p>Closed-form solutions allow fast and precise computations of the first-passage time distribution compared to the usage of approximation methods, which are necessary if the first-passage time density can only be represented by an infinite sum. However, these two choices of ρ capture essential theoretical concepts <ref type="bibr" target="#b77">(Teodorescu &amp; Usher, 2013;</ref><ref type="bibr" target="#b88">Zylberberg et al., 2012)</ref>. A value of ρ = 0 leads to an independent race of accumulators, which represents the assumption of evidence accumulation in the absence of interaction <ref type="bibr" target="#b77">(Teodorescu &amp; Usher, 2013;</ref><ref type="bibr" target="#b88">Zylberberg et al., 2012)</ref>. A negative correlation of the noise in the accumulation processes represents the assumption of feed-forward inhibition, which means that higher input values in one accumulator partially reduce the input in the other accumulator <ref type="bibr" target="#b77">(Teodorescu &amp; Usher, 2013;</ref><ref type="bibr" target="#b88">Zylberberg et al., 2012)</ref>. Note that for ρ = -1, the race model is equivalent to a drift diffusion model.</p><p>One possibility to compute confidence in the context of race models is the Balance of Evidence <ref type="bibr">(BoE, Vickers et al., 1985)</ref>, i.e., the difference in the amount of evidence in favor of the two alternatives at the time of decision. Because the winning accumulator is always at its threshold at decision time, BoE is entirely determined by the distance of the losing accumulator to its upper threshold. For instance, if R = 1, the confidence variable may thus be defined as</p><formula xml:id="formula_9">c BoE = B -X 2 (T Dec ).</formula><p>The logic behind the BoE is intuitive: the less evidence there was for the non-chosen alternative, the clearer and less ambiguous the decision resulting in a higher degree of confidence associated with the decision. However, empirical studies have shown that confidence is also affected by decision time <ref type="bibr" target="#b20">(Hellmann et al., 2023;</ref><ref type="bibr" target="#b24">Kiani et al., 2014)</ref>. In addition, it has been shown that if confidence in a race model was computed optimally, it would be a function of both BoE and decision time <ref type="bibr" target="#b39">(Moreno-Bote, 2010)</ref>. For this reason, dynConfiR includes race models with a more general confidence variable in the form of a linear combination of Balance of Evidence and the inverse of decision time. Assuming again that R = 1, confidence is computed as</p><formula xml:id="formula_10">c RM t = w X (B -X 2 (T Dec )) + w RT 1 √ T Dec + w Int B -X 2 (T Dec ) √ T Dec ,</formula><p>where the weights w X , w RT , w Int are greater than 0 and sum to 1 to form a trade-off between the possible predictor variables. Note that the fixed sum of weight parameters is not a restriction of the model because the confidence and confidence thresholds may be rescaled by the sum of weights to produce the same distribution of response time and confidence. dynConfiR implements race models with all combinations of assumptions about independent or correlated accumulators and a confidence variable that does or does not depend on decision time. The acronyms for the models used in the package are summarized in Table <ref type="table">2</ref>.</p><p>Note that the first confidence measure c BoE is a special case of the more general c RM t , if the weight parameters are set accordingly (w X = 1, w RT = w Int = 0).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 2</head><p>Acronyms for the different variations of race models used in dynConfiR.</p><p>Confidence variable</p><formula xml:id="formula_11">c BoE c RM t Correlation 0 IRM IRMt of noise (ρ) -.5 PCRM PCRMt</formula><p>The multiple-threshold log-normal race model</p><p>The MTLNR model <ref type="bibr" target="#b64">(Reynolds et al., 2020)</ref> forms a special case of racing accumulator models because it uses a simple ballistic accumulation instead of a noisy, Gaussian process <ref type="bibr" target="#b7">(Brown &amp; Heathcote, 2005)</ref>. Variation in responses and response times are the results of variation in accumulation rates and boundary distances, which are both assumed to follow a log-normal distribution.</p><p>In detail, MTLNR assume log-normally distributed boundary distances for the two accumulators (D 1 , D 2 ). The distribution is described by their logarithms, (log D 1 , log D 2 ), which follow a normal distribution with mean (µ d1 , µ d2 ) and covariance matrix</p><formula xml:id="formula_12">Σ d = σ 2 d1 σ d1 σ d2 ρ d σ d1 σ d2 ρ d σ 2 d2</formula><p>. Similarly, the accumulation rates (V 1 , V 2 ) follow a log-normal distribution with mean parameter (µ v1 , µ v2 ) and covariance</p><formula xml:id="formula_13">matrix Σ v = σ 2 v1 σv1σv2ρv σv1σv2ρv σ 2 v2</formula><p>for the underlying normal distribution on the log-rates.</p><p>Because of the linear ballistic nature of evidence accumulation, the boundary crossing times for each accumulator is determined by boundary distance and accumulation rate T i = D i /V i . The first accumulator to hit its boundary determines the decision and decision time, similar to the race models with Wiener processes.</p><p>The confidence variable in the MTLNR is defined as the logarithm of the ratio between the boundary crossing time of the loosing accumulator over the boundary crossing time of the winning accumulator. For instance, if the first accumulator hits its boundary first, confidence is computed by</p><formula xml:id="formula_14">c M T LN R = log T 2 T 1 .</formula><p>This will always lead to values greater than 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Common mechanism in forming confidence judgments</head><p>Although models may differ in their decision architecture and the specific computation for the confidence variable, the mechanism for the formation of a confidence report, as implemented in the package, is the same for all models. All models are built to produce discrete confidence outcomes C with an arbitrary number of levels K ≥ 2. To generate discrete confidence reports, the models assume that some internal confidence variable c is generated according to the formula for the respective model specified above. Confidence judgments are then determined by comparing the internal confidence variable to a set of thresholds, θ R,i , i ∈ {1, ...K -1}, depending on the choice R. Formally, the reported confidence is</p><formula xml:id="formula_15">C = K-1 i=1 1 (c&gt;θ R,i ) + 1,</formula><p>where 1 denotes the indicator function, which is one if the condition is true and zero, otherwise. This means that observers are assumed to report a confidence level of 2 on a three-point scale if the confidence variable c falls between θ R,1 and θ R,2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Non-decision time component</head><p>Similarly, all models share the assumption of a non-decision time component, which includes time for stimulus encoding and the formation of a motor response. The non-decision time component is not related to the decision mechanics itself but contributes to the observed response times. It is modeled as a <ref type="bibr" target="#b57">&amp; Tuerlinckx, 2002)</ref>. The formula for the response time depends on the timing of the confidence report in the experiment at hand. For experiments in which the choice and confidence judgment were reported sequentially, the models currently implemented in the package can only account for the choice response time and do not include the confidence response time. The choice response time is assumed to be</p><formula xml:id="formula_16">uniformly distributed component T N D ∼ Unif[t 0 , t 0 + s t0 ] (Ratcliff</formula><formula xml:id="formula_17">RT = T Dec + T N D .</formula><p>(2)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Application of models with post-decisional accumulation to data from simultaneous choice and confidence reports</head><p>If choice and confidence are reported simultaneously, then the response time is still defined as in eqn (2) for models that do not assume post-decisional accumulation of evidence. For models that assume a post-decisional accumulation period, all processes are assumed to have finished at the time of the response. Thus, the observed response time is the sum of decision time, post-decisional accumulation time, and non-decision time,</p><formula xml:id="formula_18">RT = T Dec + τ + T N D .</formula><p>(3)</p><p>However, the models with post-decisional accumulation time could also be fitted in experiments with simultaneous responses using the first definition of response time as in eqn (2) using the same fitting functions with specific arguments (see section Fitting confidence models to experimental data).</p><p>All parameters of the different models are summarized in Table <ref type="table">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Other sequential sampling models of confidence</head><p>The confidence models presented here are only a subset of previously proposed dynamical confidence models. Other models include the RTCON model <ref type="bibr" target="#b55">(Ratcliff &amp; Starns, 2009</ref><ref type="bibr" target="#b25">, 2013)</ref> or the bounded accumulation model proposed by <ref type="bibr" target="#b24">Kiani et al. (2014)</ref>. The dynConfiR package is restricted to models for which closed-form solutions are available for the joint distribution of response times and confidence, or the approximations of response time distributions are well-studied concerning their precision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 3</head><p>List and short description of all parameters for the different models.</p><p>Parameter Description dynaViTE a distance between upper and lower decision boundary for decision process z relative mean starting point of decision process s z range of uniform distribution for the relative starting point in the decision process ν mean drift rate for decision process s diffusion constant of the decision process s ν variation in drift rate of the decision process τ length of inter-rating period µ V mean drift rate for the visibility process s V diffusion constant of the visibility process σ V variation in drift rate of visibility process w weight on decision evidence for confidence variable λ exponent of accumulation time in the denominator of the confidence variable</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Race Models</head><p>A, B thresholds for the two accumulation processes µ 1 , µ 2 drift rates for the two accumulators s 1 , s 2 diffusion constants for the two accumulators ρ correlation of process noise between the two accumulators (either 0 for IRM and IRMt or -.5 for PCRM and PCRMt) w X , w RT , weights on loosing accumulator, decision time and and w Int interaction for the confidence variable MTLNR µ d1 , µ d2 mean parameters for boundary distances of the two accumulators µ v1 , µ v2 mean parameters for accumulation rates of the two accumulators σ d1 , σ d2 variance parameters for boundary distances of the two accumulators σ v1 , σ v2 variance parameters for accumulation rates of the two accumulators ρ d correlation between boundary distances ρ v correlation between accumulation rates</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Common parameters</head><formula xml:id="formula_19">t 0 minimal non-decision time component s t0 range of uniform distribution for non-decision time component θ R,k set of confidence criteria, R = -1, 1, k = 1, ..., K -1 for discretization into K steps</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Functionalities of the package</head><p>In the following, we will first describe a prototypical workflow illustrating how the package may be used for model comparison studies. Afterward, the most essential functions implemented in dynConfiR are explained in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Installation</head><p>The package is available on CRAN and may be installed with the command:</p><p>install.packages("dynConfiR")</p><p>A development version of the package is available on GitHub and may be downloaded and installed using the devtools package and the command:</p><formula xml:id="formula_20">devtools::install_github("SeHellmann/dynConfiR")</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Workflow</head><p>The dynConfiR package provides functions for model fitting, i.e., estimation of model parameters.</p><p>The function fitRTConfModels implements the full model fitting procedure and allows for parallelization over subjects.</p><p>The functions of dynConfiR are optimized for within-subjects manipulations of discriminability.</p><p>Models can be fitted independently for each subject, facilitating quantitative model comparison using information criteria like AIC and BIC <ref type="bibr" target="#b2">(Akaike, 1974;</ref><ref type="bibr" target="#b67">Schwarz, 1978)</ref>. Firstly, since models are fitted to individual participants, computing model weights on a subject-level, which is done by the function subject_modelweights, may be used to inspect models that are prominent in the group, but also to examine heterogeneity or a group-structure with respect to the best-fitting models in the data. In many cases, an conclusion on the group-level is desired. For this purpose, assuming that BIC or AIC are good approximations of model evidence, dynConfiR provides the function group_BMS_fit to conduct a group-level model comparison based on a Bayesian model selection approaches <ref type="bibr" target="#b65">(Rigoux et al., 2014)</ref>.</p><p>Cognitive modeling studies should check whether the fitted models could reproduce the main qualitative patterns of empirical data <ref type="bibr" target="#b46">(Palminteri et al., 2017)</ref>. For this purpose, the functions predictConfModels and predictRTModels compute the predicted data distributions for given parameter sets. While predictConfModels computes the discrete decision and confidence outcomes, predictRTModels provides the density for the joint distribution of decision, response time, and confidence rating. When used with previously fitted parameters, these functions can be used to visually compare the model predictions to empirical data or to check for the reproduction of qualitative data patterns. One example of a qualitative pattern that confidence models need to explain is the relationship of mean confidence in discrimination tasks with increasing stimulus discriminability for correct and incorrect decisions, which have been referred to as a so-called folded-X or a double increase pattern <ref type="bibr" target="#b62">(Rausch &amp; Zehetleitner, 2019)</ref>. The workflow for parameter fitting, model comparison, and prediction is summarized in Figure <ref type="figure">1</ref>.A step-by-step tutorial on how to use the package in a modeling study is available on the GitHub page of the package and downloadable as a R markdown document at OSF. We also illustrate the workflow in section Example of Application in Model Comparison. In addition to classical model comparison studies, the fitted parameters for the individual subjects can be used for group comparisons and correlational analyses, for example, to study the relationship of specific parameters with measures of metacognitive sensitivity or neurological data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1</head><p>Basic workflow and functions for model comparison studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parameter fitting</head><p>Fit each model to each subject independently (function: fitRTConfModels)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prediction</head><p>Predict behavior from models using fitted parameters (functions: predictConfModels and predictRTModels; input=output from fitRTConfModels)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Quantitative model comparison</head><p>using information criteria (BIC, AIC, AICc) (functions: subject_modelweights for individual-level model probabilities and group_BMS_fits for group-level Bayesian model selection; input=output of fitRTConfModels)</p><p>ghgh</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Qualitative model comparison</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Visual model comparison by plotting predictions and empirical data</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fitting confidence models to experimental data</head><p>In this section, we describe the fitting function in more detail, starting with which experimental data can be used, how parameters are mapped to the manipulations, and finally, the fitting procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental paradigm</head><p>The fitting functions in the package are tailored to perceptual, binary discrimination tasks with a single difficulty manipulation. This is a standard paradigm in the study of computational models of confidence <ref type="bibr" target="#b24">(Kiani et al., 2014;</ref><ref type="bibr" target="#b50">Rahnev et al., 2020;</ref><ref type="bibr" target="#b59">Rausch et al., 2018)</ref>. For other manipulations that are assumed to vary specific parameters only, the user can write their own likelihood and fitting functions using the density functions described later. For instance, manipulations of the speed-accuracy trade-off <ref type="bibr" target="#b11">(Desender et al., 2021)</ref> and post-decisional accumulation period <ref type="bibr">(Desender et al., 2022;</ref><ref type="bibr" target="#b38">Moran et al., 2015)</ref> may also be interesting when studying the formation of confidence. Still, when all model parameters are allowed to vary across conditions, the fitRTConfModels function remains applicable. In such instances, the user can specify a data column as the subject identifier, which differentiates between combinations of subjects and manipulation levels such that the fitting function fits separate sets of parameters per subject and condition. Fitting independent parameter sets for each condition can be useful for critically testing the assumption that an experimental manipulation selectively influences specific parameters <ref type="bibr" target="#b30">(Lerche &amp; Voss, 2019;</ref><ref type="bibr" target="#b82">Voss et al., 2004)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data format</head><p>The fitting function expects the data to come in a tidy data frame, with each row representing one trial. The data frame should include the following columns (expected column names in parentheses): true stimulus identity (stimulus), binary decision response (response), categorical confidence judgment (rating), and response time (rt). As an alternative to the stimulus or response column, a column for accuracy (correct) may be provided. In addition, a column for the experimental manipulation of discriminability of the stimulus (condition) may be included but is not necessary. Instead of renaming columns in the data frame, alternative column names may be added as arguments of the form rating = "confidence", if, for example, the column indicating the confidence rating is called confidence. A column named sbj, subject, or participant may be included to fit the models independently to individual subjects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fitted parameters</head><p>The stimulus and response categories are denoted by S, R ∈ {-1, 1}, and task difficulty is assumed to be manipulated in L steps. A discrimination parameter, d l , l = 1, . . . , L, is fitted independently for each difficulty level. Thus, the condition column will be transformed into a factor, even when numeric values are supplied. In the confidence models, the drift rates of the different processes depend on the stimulus identity and the discriminability parameter of the difficulty level of the trial: For dynaViTE, the mean drift rate of the decision process is set to ν = Sd l , and the mean drift rate of the visibility process is set to</p><formula xml:id="formula_21">µ V = d l .</formula><p>For the race models, the drift rates are set to (µ 1 , µ 2 ) = (Sd l , -Sd l ). This means that the first accumulator accumulates evidence for the first category, while the second one accumulates evidence for the category S = -1. For MTLNR, the mean parameters for the accumulation rates are set to</p><formula xml:id="formula_22">(µ v1 , µ v2 ) = (d l , 0), if S = 1 and to (µ v1 , µ v2 ) = (0, d l ), if S = -1.</formula><p>All other parameters are assumed to be independent of the task difficulty manipulation and fitted for each subject. However, the diffusion constant of the decision process in dynaViTE s and the diffusion constants of the two processes in the race models, σ 1 and σ 2 , are fixed to 1 because other parameters may be scaled accordingly to produce the same likelihoods. This is a common approach in response time modeling <ref type="bibr" target="#b28">(Lerche &amp; Voss, 2016;</ref><ref type="bibr" target="#b53">Ratcliff &amp; Rouder, 1998)</ref>. In the MTLNR, the variance parameters for the boundary distances σ d1 and σ d2 and their correlation ρ d are fixed to 0, such that only the variance parameters for the accumulation rates are fitted. Therefore, the variance component are simply labeled s 1 and s 2 for the variance parameters of the boundary hitting times of the first and second accumulator, and ρ for their correlation. This is in accordance with the implementation of the MTLNR in <ref type="bibr" target="#b64">Reynolds et al. (2020)</ref>. Importantly, when we implemented the model with all parameters fitted freely, we observed that the variance parameters could not be well-recovered and also model recovery was worse.</p><p>Whether choice and confidence were reported simultaneously or sequentially is determined by the simult_conf argument, which should be set to TRUE if the reports were given simultaneously and FALSE otherwise.</p><p>The number of confidence thresholds θ R,k , k = 1, . . . , K -1 separating the internal confidence variable into discrete steps depends on the number of possible levels for the discrete confidence rating K.</p><p>The confidence thresholds can vary between choice responses by default, leading to 2(K -1) fitted confidence threshold parameters. We recommend specifying the nRatings argument to provide the number of confidence levels because not every subject might have used the full range of the scale. Alternatively, the ratings column can be provided as a factor with factor levels representing the possible rating outcomes. If not all confidence levels were used, the number of fitted parameters is reduced internally because the maximum likelihood is attained by some thresholds being identical in this case. If the lowest (or highest) confidence level was not used, then the likelihood is maximized by setting the lowest confidence threshold to minus infinity (or the highest threshold to infinity). If an intermediate confidence category was not used, then the likelihood is maximized by two confidence thresholds being identical. Therefore, the concerned confidence thresholds do not need to be optimized numerically by the optimization procedure but may be set afterward to speed up the optimization. The nRatings argument is required to correctly format the output parameters and report the right number of fitted parameters.</p><p>To sum up, the total number of parameters depends on the number of steps in the manipulation L and the number of levels for the discrete confidence rating, K. This means that for dynaViTE, there are 11 + L + 2(K -1) parameters. In the race models with a time-dependent confidence variable, there are 6 + L + 2(K -1) parameters. Two of three weight parameters have to be fitted, while the third weight is determined by the sum of the weights being 1. In addition, the correlation parameter ρ is not estimated but fixed at -0.5 for PCRMt and 0 for IRMt. For MTLNR, the number of fitted parameters is equal to 7 + L + 2(K -1). For special cases like 2DSD or race models with a time-independent confidence variable, the number of parameters is reduced by the number of fixed parameters. In addition, if the confidence thresholds are assumed to be symmetric for the two response options (by setting fixed=list(sym_thetas=TRUE)), the number of parameters is reduced by K -1.</p><p>Which models should be fitted is specified by the models argument. The function fitRTConfModels allows for all models presented in the section Sequential sampling confidence models: dynaViTE, dynWEV, 2DSD, DDConf, IRMt, PCRMt, IRM, and PCRM. In addition, the user may fix individual parameters by providing the argument fixed in the form of a list. For instance, researcher may want to assume an unbiased observer by setting z = 0.5 for the drift diffusion-based models and A = B for the race models. Moreover, specifying sym_thetas=TRUE in the list leads to symmetric confidence thresholds for the two choice possibilities, i.e., θ 1,k = θ -1,k ∀k = 1, . . . , K -1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fitting procedure</head><p>The function fitRTConfModels fits the models specified in the models argument to each individual subject in the data set using maximum likelihood estimation, i.e., by minimizing the negative log-likelihood of model parameters. The likelihood is computed under the assumption of independent observations, which means that for trials i = 1, ..., N ; the vectors for presented stimulus identity S and task difficulty D; and the vectors for observed outcomes response time RT , confidence rating C, and response R, the negative log-likelihood of a set of parameters ϑ is computed as</p><formula xml:id="formula_23">L(RT, C, R|ϑ, S, D) = - N i=1 log P(RT i , C i , R i |ϑ, S i , D i ).</formula><p>The optimization procedure starts with a grid search, in which the likelihood is computed for a broad range of possible parameter combinations. The best-performing parameter sets identified in the initial grid search are used as starting values for the optimization algorithm. The optimization algorithm is restarted several times with the previous run's output as the next run's starting point to allow the optimization to avoid local minima. The number of initial values and restarts for the optimization procedure can be set by the user using the opts argument. The functions offer the possibility of parallelization over both subject-model combinations and within one fitting procedure over the starting values for the optimization.</p><p>The output is a data frame with one row for each combination of subject and fitted model. The columns of the output data frame are the fitted model parameters together with additional information, like the number of trials (N), fixed parameters (fixed) and the following performance measures: the final negative log-likelihood and model selection criteria AIC, AICc, and BIC.</p><p>On the one hand, the maximum-likelihood fitting procedure implemented in fitRTConfModels is an efficient way for estimating parameters using all the available information in the data without aggregating to quantiles <ref type="bibr">(Lerche et al., 2017;</ref><ref type="bibr" target="#b81">Voss et al., 2013)</ref>. On the other hand, the maximum likelihood method is known to be influenced by contaminant response times, which are not generated by a DDM <ref type="bibr">(Lerche et al., 2017;</ref><ref type="bibr" target="#b57">Ratcliff &amp; Tuerlinckx, 2002)</ref>. Therefore, it is recommended to apply a filter on trials at the level of the individual subject, e.g., by removing trials with response times that are either below a certain threshold (e.g., 300 ms) or which deviate significantly from the mean or median of the response time distribution (e.g., response times, which exceed the mean plus two standard deviations <ref type="bibr">;</ref><ref type="bibr" target="#b20">Hellmann et al., 2023;</ref><ref type="bibr" target="#b48">Pleskac &amp; Busemeyer, 2010)</ref>. There are different strategies for removing contaminants in the data. Some studies use hard cut-offs <ref type="bibr">(Lerche &amp; Voss, 2017;</ref><ref type="bibr">Ratcliff et al., 2004;</ref><ref type="bibr" target="#b79">van den Berg et al., 2016)</ref>, others use exclusion criteria based on the interquartile range <ref type="bibr" target="#b30">(Lerche &amp; Voss, 2019;</ref><ref type="bibr" target="#b81">Voss et al., 2013)</ref> or alternatively, a mixture of hard cut-off for the fast responses and a distribution-dependent cut-off for slow responses <ref type="bibr" target="#b20">(Hellmann et al., 2023</ref><ref type="bibr" target="#b21">(Hellmann et al., , 2024;;</ref><ref type="bibr">Lerche et al., 2017;</ref><ref type="bibr" target="#b38">Moran et al., 2015;</ref><ref type="bibr" target="#b48">Pleskac &amp; Busemeyer, 2010)</ref>. However, it is hard to suggest general guidelines for exclusion criteria that suit all experiments. For new experiments, we recommend using pilot data to infer suitable exclusion criteria because different experimental paradigms produce different response time distributions. In light of ongoing replication issues in psychology <ref type="bibr" target="#b66">(Röseler et al., 2024)</ref>, we recommend to pre-register exclusion criteria and check whether results are robust concerning the specific choice of exclusion criteria <ref type="bibr" target="#b85">(Wagenmakers et al., 2012)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Predicting confidence and response time distributions</head><p>The empirical data is often compared visually to model predictions to check for qualitative mismatches. For this purpose, dynConfiR includes the functions predictConfModels (for the discrete decision and confidence distribution) and predictRTModels (for the joint distribution of response time, decision and confidence). These take data frames with parameters as input. Notably, the output of the fitting procedure may be inserted directly into the prediction functions. predictConfModels returns a data frame with columns for stimulus identity, response, and confidence judgments and a column indicating the probability of an outcome. predictRTModels has an additional column for the response time, spanned equidistantly for a user-provided interval. If the input has more than one row, columns for subject ID and model are required, and the output will be accordingly structured by binding the data frame outputs for each subject and model combination one below the other. Similarly to the fitting function, participant, subject, and sbj column names are accepted as identifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Quantitative model comparison using information criteria</head><p>Beside the qualitative and visual inspection of model fits, a quantitative model comparison and model selection is often conducted to compare models when qualitative data patterns are not diagnostic <ref type="bibr" target="#b15">(Farrell &amp; Lewandowsky, 2018)</ref>. The information criteria BIC, AIC, and AICc, are used to approximate the negative log-model evidence, such that Bayesian approaches for model comparison may be used. On a subject level, these information criteria can be directly transformed into model weights to assess the prevalence of certain models, but also heterogeneity within the sample. This is done by the function subject_modelweights, which takes a data frame with columns for model names, subject identifier (one of participant, subject, or sbj), and the information criterion that should be used as input. The second argument measure gives the name of the column with the information criterion and is "BIC" by default.</p><p>Therefore, the output of a fitRTConfModels call may be directly be used as argument for the function subject_modelweights.</p><p>Similar to the subject-level model comparison, the function group_BMS_fits takes the result of model fitting but performs a group-level Bayesian model selection based on a random effects model of model prevalence across subjects <ref type="bibr" target="#b65">(Rigoux et al., 2014;</ref><ref type="bibr" target="#b73">Stephan et al., 2009)</ref>. The random effects model assumes a Dirichlet distribution for model probabilities in the population, for which the α parameter is estimated based on Variational Bayesian approach and algorithm described in <ref type="bibr" target="#b73">Stephan et al. (2009)</ref>. The estimated parameter may be used to calculate models' exceedance probabilities. The exceedance probability of a model is defined as probability that the model has a higher probability compared to all other models given the Dirichlet distribution. The function also provides a scaled version of the exceedance probabilities, the protected exceedance probabilities (PEP). PEP controls for the Bayesian omnibus risk (BOR), which quantifies the risk of assuming the random effects model in contrast to a null-model, in which all models have always the same prior probability, i.e. the limit of a Dirichlet model with an α parameter with equal components that approach infinity. The estimation of BOR is based on a Variational approach and the implementation is based on the VBA toolbox for Matlab <ref type="bibr" target="#b9">(Daunizeau et al., 2014)</ref>.</p><p>In addition to the protected exceedance probability, and exceedance probability, the function group_BMS_fits calculates the model probabilities based on a fixed effect model, that assumes that there is a single-best model in the population. The latter is equivalent in calculating model weights based on the sum of BIC values across all participants. By default, model comparison is performed using the BIC. Using the second argument, measure, one could base the comparison also on the AIC or AICc in both functions.</p><p>We decided to use the BIC as the default as it is the most conservative criterion for the number of data points that are usually used in studies modeling response times.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Other functions</head><p>Probability density functions ddynaViTE(response, rt, th1, th2, a, v, t0, ...) dPCRM(response, rt, th1, th2, mu1, mu2, a, b,...)</p><p>The implemented confidence and response time distributions form the basis for model fitting and predictions. The distributions are implemented as probability densities in C++ and accessed in R using</p><p>Rcpp. The usage of the different density functions is very similar. The first arguments represent the outcome variables: response time (RT ), the binary choice (R), and the interval for the confidence variable (θ 1 and θ 2 ). The density functions return the probability P model (RT, R, c model ∈ [θ 1 , θ 2 ]|ϑ). The model parameters are passed as additional, individual parameters. Note that θ 1 and θ 2 are also parameters usually estimated during model fitting. The densities for drift diffusion-based models are approximated using the truncated series for the density of the drift diffusion model (see <ref type="bibr" target="#b42">Navarro &amp; Fuss, 2009;</ref><ref type="bibr" target="#b82">Voss et al., 2004)</ref>. The densities for the race models are implemented according to the formulas in Moreno-Bote (2010), which are derived using the methods of images for the stochastic differential equation. The integration over the distribution of starting points and non-decision time components is conducted numerically using a rectangular approximation with equidistant steps (see Precision analysis section). The density functions may be used for theoretical calculations and to implement other model fitting algorithms instead of the maximum likelihood estimation procedure included in dynConfiR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Log-likelihood functions</head><p>LogLikWEV(data, paramDf, model = "dynaViTE", simult_conf = FALSE,...) LogLikRM(data, paramDf, model = "IRM", time_scaled = FALSE,...)</p><p>There are also functions for calculating the log-likelihood of a data set given some parameters for each model. The two main arguments are data, a data frame of the empirical data with the stimulus, response, response time and confidence, and paramDf, a data frame with one row and columns for the required parameters of the chosen model. The log-likelihood function is included in dynConfiR mainly to allow for the investigation of the impact of experimental manipulations on specific parameters or other relationships between stimulus discriminability and mean drift rate. For example, previous studies assumed a power function for the relationship between physical stimulus intensity and internal signal strength <ref type="bibr" target="#b58">(Ratcliff et al., 2018;</ref><ref type="bibr" target="#b76">Teodorescu et al., 2016)</ref> instead of fitting discriminability parameters for each level of the experimental manipulation. The likelihood functions are wrappers of the density functions that can be used easily in custom built cost-functions for optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simulation functions</head><p>rdynaViTE(n, a, v, t0 = 0, z = 0.5, d = 0, sz = 0, sv = 0, st0 = 0, tau = 1, w = 0.5, ...) simulateRTConf(paramDf, n = 10000, model = NULL, gamma = FALSE, agg_simus = FALSE ,...)</p><p>The package includes low-level and high-level simulation functions. Because simulation is based on a discretization of the stochastic differential equation, there is an argument delta determining the step-size of the discretization and an argument maxrt, which determines the maximal simulated decision time. The simulation of a single trial is stopped when the stopping criterion has not been met and the maximum decision time has been exceeded. When the simulation is stopped without a choice, a response of 0 is returned. First, the low-level simulation functions are similar to the simulation functions of other probability distributions in R , e.g., rdynaViTE and rPCRMt, with arguments for each parameter, most of them having default values.</p><p>A high-level function for simulating data with fitted parameters is also available. The function simulateRTConf takes a data frame with one row and columns for the required parameters. The high-level function simulates n trials per stimulus identity (which stimulus identity is used for the simulation may be changed with the stimulus argument) and difficulty condition. The number of difficulty levels is determined by the number of drift rates in the paramDf argument. To simplify the application to several parameter sets and models, the model argument can be given as a column in the paramDf argument. In addition, simulateRTConf offers the possibility to aggregate the output over response times, i.e., reporting only the discrete outcomes of choice and confidence. Finally, when gamma=TRUE, the function computes Kruskal's Gamma <ref type="bibr" target="#b43">(Nelson, 1984)</ref> between confidence and several other relevant variables, e.g., between confidence and accuracy for different levels of stimulus discriminability. If gamma=TRUE is used, the output is a list with two components: simus for the data frame with the actual simulated data and gamma with several data frames for different Gamma correlations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example of Application in Model Comparison</head><p>Now, we present a complete example of an analysis including a model comparison. The data set for this demonstration was generously published by Law &amp; Lee <ref type="bibr" target="#b44">(Ng et al., 2021)</ref> and was downloaded from the confidence database <ref type="bibr" target="#b50">(Rahnev et al., 2020)</ref>. The data set is available at <ref type="url" target="https://osf.io/vgr27">https://osf.io/vgr27</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental method</head><p>The study was initially conducted to investigate serial dependence in confidence judgments using random-dot kinematograms. 16 participants reported their perceived motion direction, which was either leftwards or rightwards, simultaneously with their confidence using the keyboard. Confidence was reported on a 4-point scale.</p><p>Task difficulty was manipulated by varying motion coherence. In a 240-trial calibration phase, coherence values for target accuracy levels of .52, .65, and .78 were determined using a staircase technique.</p><p>The resulting coherence values were then used in the experimental phase for coherence levels 1, 3, and 5, respectively, while the coherence values for the second and fourth levels of the manipulation were determined by averaging the values for the first and third level and the third and fifth level, respectively.</p><p>The experimental trials consisted of 20 blocks with 60 trials each. Because of the primary aim of the study, trials with medium difficulty, i.e., a coherence level of 3, were always preceded by either one or two trials with either high (level 1) or low (level 5) difficulty. This trial-by-trial dependency will be ignored in the following analysis.</p><p>Participants did not receive trial-by-trial feedback but instead received feedback at the end of each block about both their overall accuracy and their accuracy in the previous block.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data</head><p>After downloading the data from the confidence database, we selected the relevant columns, converted their names to lowercase, and removed the calibration trials from the data set. We then renamed the columns for the subject ID to participant (note that the functions accept the column names subject and sbj as well) and response times to rt. As confidence was measured on a 4-point scale, we did not have to bin the rating response. The resulting data set has the following form.</p><p>&gt; head(Data)</p><p>participant stimulus response confidence rt coh_level coherence 1 1 1 2 3 2.7568960 1 0.1146677 2 1 2 2 3 0.5194411 1 0.1146677 3 1 2 2 4 0.4860291 3 0.1998495 4 1 1 2 4 3.0795050 4 0.5150529 5 1 1 2 4 0.5935152 5 0.8302563 6 1 2 1 4 0.3307259 5 0.8302563 &gt; dim(Data)</p><p>[1] 15360 7</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data preprocessing</head><p>A typical step before fitting sequential sampling models is to remove possible outliers from the empirical response time distribution. Filtering individual data by response times is recommended because the maximum likelihood method, which is used by dynConfiR, is known to be specifically influenced by outliers, and there is no implementation of lapses in the current version of the package.</p><p>We removed responses that were faster than the median minus one standard deviation and slower than the mean plus 4 standard deviations for each participant, resulting in the removal of 1.7% of all trials.</p><p>In the second step, we removed one participant because they did not perform above chance (0.53 compared against 0.5), which delivered no evidence of being above chance in a Bayesian proportion test against chance level accuracy with a prior scale conducted via the proportionsBF function from the BayesFactor package <ref type="bibr" target="#b40">(Morey et al., 2024)</ref> with a prior scale parameter of 0.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analyses</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model fitting</head><p>We wanted to conduct a model comparison on the data, comparing a broad range of possible models. We considered models previously compared on similar datasets from visual discrimination experiments: dynaViTE, dynWEV, 2DSD, PCRMt, and IRMt <ref type="bibr" target="#b20">(Hellmann et al., 2023</ref><ref type="bibr" target="#b21">(Hellmann et al., , 2024))</ref>. Note that although we did not explicitly fit all models, simpler models are special cases of the models fitted in this section. For instance, race models with time-independent confidence variables, IRM and PCRM, are special cases of IRMt and PCRMt, respectively. In addition, we fitted the MTLNR model, which was not previously compared to the above models on empirical data. The first step was to fit the model parameters for each participant, which was achieved with the following command:</p><p>parfits &lt;-fitRTConfModels(Data, models=c("dynaViTE", "dynWEV", "2DSD", "PCRMt", "IRMt", "MTLNR"), nRatings=4, restr_tau = "simult_conf", opts=list(nAttempts=4, nRestarts=4), parallel="both", n.cores = c(5, 4), condition = "coh_level", rating="confidence")</p><p>The function fitRTConfModels splits the data for the participant column and fits each of the models given in the respective models argument. Providing nRatings=4 ensured that three confidence thresholds are fitted for participants that did not used the full range of the confidence scale. The argument restr_tau="simult_conf" indicates that choice and confidence responses were reported simultaneously.</p><p>The argument opts is optional and allows for adaptations of the fitting procedure. We used only the four best parameter sets (default: 5) from the initial grid search as starting values for the optimization routine and started the optimization algorithm with a broad trust region four times (default: 5).</p><p>With the combination of parallel=TRUE and n.cores=c(5,4), we distributed the fitting procedure across different CPUs, fitting five participants in parallel with four cores per participant.</p><p>Therefore, for each participant, the four optimization routines with the different initial parameter settings were run in parallel.</p><p>Finally, it was necessary to include column names that deviate from the default ones, which was achieved with the last two arguments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Quantitative model comparison</head><p>With few lines of code, the first central part of the analysis was achieved. With the outputs, a quantitative model comparison may be conducted using the information criteria available in parfits.</p><p>Information criteria for models that were fit to participants independently could be used in different ways for model comparison. Model comparison could be performed on the participant-level by calculating BIC weights independently for each participant. This approach may already indicate dominating individual models but is also able to represent heterogeneity across participants or groups of participants. Still, sometimes it is desirable to investigate the performance of models on a group-level. The results for both analysis levels are easily obtained by using the functions subject_modelweights respectively group_BMS_fits with using parfits as input.</p><p>BICweights &lt;-subject_modelweights(parfits) groupBMS &lt;-group_BMS_fits(parfits)</p><p>In the following, we visualize only the results based on the BIC. The dynConfiR package also includes AIC and AICc in the output, which are not visualized here because the results are almost identical. On a participant-level, the dynaViTE model provided the best account for 9 out of 15 participants, while the MTLNR model provided the best account for 3 participants (Figure2, upper panel).</p><p>Visualizing the average BIC values over the sample, we see that the MTLNR and therace models achieved </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prediction and visual model fit</head><p>The output of the fitting function may be passed directly to the prediction functions, which also use parallelization over participants.</p><p>The prediction functions automatically split the first data frame argument by the participant and model columns and select the respective prediction function for the model of each row. prediction_ConfDist &lt;-predictConfModels(parfits, simult_conf=TRUE, parallel = TRUE) prediction_RTConfDist &lt;-predictRTModels(parfits, simult_conf=TRUE, maxrt=6, scaled=TRUE, DistConf = prediction_ConfDist, parallel=TRUE) Furthermore, visualizations may be generated with the predictions to compare model fits with empirical distributions. The output of the function predictConfModels has the following form (note that only the first digits are printed for readability): &gt; print(head(prediction_ConfDist), row.names=FALSE) condition stimulus response correct rating p info err model participant 1 1 1 1 1 0.033 OK 7.9e-05 dynaViTE 1 2 1 1 1 1 0.033 OK 7.9e-05 dynaViTE 1 3 1 1 1 1 0.029 OK 7.7e-05 dynaViTE 1 4 1 1 1 1 0.020 OK 7.4e-05 dynaViTE 1 5 1 1 1 1 0.014 OK 7.1e-05 dynaViTE 1 1 -1 1 0 1 0.031 OK 7.8e-05 dynaViTE 1</p><p>In the above data frame, p represents the probability of a confidence rating and response given the stimulus identity and discriminability condition in the respective row. The columns info and err reproduce the output of the call to integrate used to compute the probabilities. We can compare the predicted distribution to the observed data distribution (see Figure <ref type="figure">3</ref>), which can be used to assess the overall precision of the model fit. It seems that all models fitted the overall data pattern well. The strongest deviation is the overestimation of low confidence response for easy conditions in the MTLNR. In addition, there is generally a slight overestimation of low confidence for correct leftward responses in easy conditions, particularly in the race models (IRMt and PCRMt). In addition, for difficult stimuli, the probability of very low confidence was underestimated, while it was overestimated for high confidence.</p><p>Interestingly, for all other conditions, there was a tendency to underestimate confidence in the leftward motion choices (second and third column) but an overestimation of confidence for rightward motion choices (first and fourth column). Participants seem to have shown a motion-dependent confidence bias leading to higher confidence ratings for correct leftwards motion responses compared to rightwards motion responses, which all the models, but particularly the three race-based models, were not able to capture very accurately (Appendix Figure <ref type="figure" target="#fig_14">A2</ref>).</p><p>Using the full response distribution, it is possible to aggregate on different levels to examine specific data patterns. One possibility is to visualize the increase in accuracy with easier decisions (Figure <ref type="figure">4</ref>, top row), for which the MTLNR shows a strong underestimation of accuracy in medium to high discriminability trials. Researchers might also be interested in the relationship between confidence and stimulus discriminability for correct and incorrect decisions (Figure <ref type="figure">4</ref>, bottom row). In the present example, we see increasing mean confidence with higher stimulus discriminability for both correct and incorrect decisions, which is referred to as a double-increase pattern <ref type="bibr" target="#b62">(Rausch &amp; Zehetleitner, 2019)</ref>. Many computational models of confidence are not able to produce such a pattern but can only account for a negative relationship between confidence and discriminability in incorrect decisions, resulting in the folded-X pattern <ref type="bibr" target="#b20">(Hellmann et al., 2023;</ref><ref type="bibr" target="#b59">Rausch et al., 2018</ref><ref type="bibr" target="#b63">Rausch et al., , 2020))</ref>. One example of a model that only accounts for a folded-X pattern is the 2DSD model, which also showed this pattern in the present example.</p><p>Although the PCRMt and IRMt are in principle able to account for a double-increase pattern, they showed a flat curve for incorrect responses, indicating constant confidence across difficulty levels for incorrect choices. Finally, also the MTLNR produces a folded-X pattern. The dynWEV model underestimated the steepness of the increase in confidence for incorrect decisions. The dynaViTE model showed the most pronounced double-increase pattern but overall overestimated confidence in incorrect decisions.</p><p>To compute the predicted response time distributions for the fitted parameters, dynConfiR offers the predictRTModels function, which, similarly to the predictConfModels, computes the joint distribution of choice, confidence rating, and response time for each level of stimulus identity and discriminability. The dens column represents the defective distribution of response times, i.e., the integral of the density for each confidence rating and response is not 1 but equals the probability of the respective choice and confidence report. With the argument scaled=TRUE, the correctly scaled densities (densscaled) are computed by dividing the defective density values by the probability of the respective discrete response. For this purpose, an additional argument (DistConf) may be provided by passing the output of predictConfModels to prevent the repeated computations of the discrete distributions. Note that the DistConf argument must have the same participants, models, and response and stimulus coding used for the models as the first argument. The resulting data frame has the following form:</p><p>&gt; print(head(prediction_RTConfDist), row.names=FALSE) condition stimulus response correct rating rt dens densscaled model participant 1 1 1 1 1 0.000 0.000 0.0 dynaViTE 1 1 1 1 1 1 0.061 0.035 1.0 dynaViTE 1 1 1 1 1 1 0.121 0.046 1.4 dynaViTE 1 1 1 1 1 1 0.182 0.053 1.6 dynaViTE 1 1 1 1 1 1 0.242 0.059 1.8 dynaViTE 1 1 1 1 1 1 0.303 0.064 1.9 dynaViTE 1</p><p>In the decision-making literature, response time distributions are commonly visualized using quantiles (Figures 6 and 5 <ref type="bibr" target="#b54">Ratcliff &amp; Smith, 2004)</ref>. For convenience, the package includes the function PDFtoQuantiles, which computes quantiles from a vector of probability density values. It also allows for data frame inputs with several columns that may be used as groups (like computing quantiles for different experimental conditions or participants). The relationship between task difficulty and response times was rather weak in the present example, illustrated by the flat quantile curves in Figure <ref type="figure">5</ref>. Response times slightly decreased for easier stimuli, which was captured by all models. Here we see that the most notable deviation from the data is produced by the MTLNR in the correct choices for the easiest condition, for which the MTLNR underestimates the lower tail of the distribution. Concerning the relationship of confidence with response times, there was a weak negative relationship, which was more pronounced in incorrect choices (Figure <ref type="figure">6</ref>). This pattern was again well captured by all models. The most pronounced deviations are visible in incorrect choices, for which the race models slightly overestimated the decrease in response times in the upper quantiles, and the 2DSD model did not reproduce the speed up for the lowest quantile in high confidence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Exploratory analysis: Fixing model parameters</head><p>The drift diffusion-based models, i.e., DDConf, 2DSD, dynWEV, and dynaViTE, include all between-trial variability parameters. It is easy to fit these models additionally without allowing for between-trial variability in the starting point and non-decisional time by setting the respective parameters to 0 in the fitting routine. The following code demonstrates the fixed argument. We additionally fixed the diffusion constant in the visibility process for dynWEV and dynaViTE to 1, equal to the diffusion constant in the decision process. Note fixing any parameter only affects the models, which include those parameters.</p><p>After the model fitting procedure, we renamed the models for the more restricted versions and combined all parameter fits in one data frame.</p><p>parfits_fixed &lt;-fitRTConfModels(Data, models=c("dynaViTE", "dynWEV", "2DSD"), nRatings=4, restr_tau = "simult_conf", fixed = list(sz=0, st0=0, svis=1), opts=list(nAttempts=4, nRestarts=4), parallel="both", n.cores = c(5, 4), condition = "coh_level", rating="confidence") parfits_fixed[, setdiff(names(parfits), names(parfits_fixed))] &lt;-NA allfits &lt;-rbind(parfits, mutate(parfits_fixed, model = paste0(model, " (fixed)")))</p><p>The quantitative comparisons show that the restricted dynaViTE model performed best on an average level as well as for six individual participants, while the full dynaViTE model still fitted best for seven participants. Although the restricted dynWEV and the PCRMt model still had the second and third best average BICs, no participant was best fit by either model. This illustrates again that quantitative model comparisons can lead to different results when performed on a group level compared to the individual participant level (Figure <ref type="figure" target="#fig_3">7</ref>). Over the extended set of models, the fully flexible dynaViTE still achieved a PEP of .75, the restricted version of the dynaViTE a PEP of .17, and the full 2DSD of .03.</p><p>Concerning the visual model fit, the restricted models did not deviate strongly from the more complex models (Appendix Figures <ref type="figure">A3-A5</ref>).</p><p>selected_models &lt;-c("dynaViTE (fixed)", "IRMt", "PCRMt", "dynWEV (fixed)") selected_fits &lt;-subset(allfits, model %in% selected_models) PCRMt IRMt dynaViTE dynWEV 2DSD MTLNR 0.6 0.7 0.8 Mean Accuracy Observed Predicted 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 2.0 2.3 2.6 Motion coherence level Mean confidence rating Observed Correct Wrong Predicted Correct Wrong Figure 4 Accuracy (top row) and mean confidence rating (bottom row) for empirical data (points and triangles) and Response time quantiles for observed (points) and predicted (lines) response time distributions across correct and incorrect decisions (columns) and confidence ratings (x-axis). Probabilities for quantiles: .1, .5, .9. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parameter recovery analysis</head><p>In order to compare fitted model parameters between groups or within subjects across different experimental conditions, it is necessary that the estimation of model parameters is robust. To assess the robustness of the model fitting procedure, we conducted a parameter recovery analysis using artificial data sets for the four most general models: dynaViTE, PCRMt, IRMt, and MTLNR, which include other models implemented in dynConfiR as special cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>To assess parameter recovery, we generated artificial data sets using known parameter values and then refitted each model to the simulated data. This procedure allowed us to evaluate how well the recovered parameters matched the generating ones. We assumed five confidence levels (K = 5) and five stimulus discriminability levels (L = 5), resulting in 26 fitted parameters for dynaViTE, 21 for IRMt and PCRMt, and 22 for MTLRN. Generating parameter sets were drawn from previous empirical model fits <ref type="bibr" target="#b20">(Hellmann et al., 2023</ref><ref type="bibr" target="#b21">(Hellmann et al., , 2024;;</ref><ref type="bibr" target="#b44">Ng et al., 2021;</ref><ref type="bibr" target="#b45">Orchard et al., 2022;</ref><ref type="bibr" target="#b69">Shekhar &amp; Rahnev, 2021)</ref>. Confidence thresholds were not taken directly from these fits but were instead computed from quantiles of the simulated confidence variable, ensuring all confidence levels were represented.</p><p>Parameter recovery was evaluated across different data set sizes (50-500 trials per condition) using the concordance correlation coefficient (CCC; <ref type="bibr" target="#b32">Lin, 1989)</ref> as a measure of agreement between generating and recovered parameters. Full methodological details and preprocessing steps are provided in the Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Figure <ref type="figure">8</ref> illustrates the parameter recovery performance as measured by the concordance correlation coefficients across model parameters (also see Appendix Figures B1-12 for more detailed results). The results indicate that the decision-related parameters are generally more robust to recover for all models but the MTLNR.</p><p>In dynaViTE, the only choice-specific parameter that is hard to recover is the between trial variability in starting point (sz). Concerning the confidence-related parameters in dynaViTE, only the diffusion constant in the visibility accumulation (s V is ) has a relatively low CCC, which requires at least 200 trials per condition and stimulus identity (2,000 trials in total) to achieve a CCC of .57. A possible solution to improve the robustness of parameter fitting might be to fix s V is to 1, similar to the diffusion constant in the decision process.</p><p>For race models, the confidence thresholds show a slightly lower recovery rate, although the general recovery is relatively good, even with fewer trials. The recovery of the confidence thresholds may also be increased by assuming a parametric relationship between them instead of fitting each threshold independently and only restricting them to be monotonic.</p><p>In MTLNR, the decision parameters show in general slightly worse but still satisfying recovery.</p><p>Importantly, the recovery does not strongly improve with the number of trials.</p><p>Figure <ref type="figure">9</ref> shows the time it took to fit the parameters to each data set. This illustrates that, without parallelization, fitting times may exceed several hours for large data sets, which limits the application of the package in such situations to machines with sufficient computing power. In addition, the MTLNR and dynaViTE models take considerably longer compared to PCRMt and IRMt with fitting times exceeding 48 hours for big data sets.</p><p>Trials per condition and and stimulus 50 100 200 500 Model dynaViTE PCRMt IRMt MTLNR Decision Confidence Decision Confidence Decision Confidence Decision Confidence q</p><formula xml:id="formula_24">-1 1 q -1 2 q -1 3 q -1 4 q 1 1 q 1 2 q 1 3 q 1 4 q -1 1 q -1 2 q -1 3 q -1 4 q 1 1 q 1 2 q 1 3 q 1 4 q -1 1 q -1 2 q -1 3 q -1 4 q 1 1 q 1 2 q 1 3 q 1 4 q -1 1 q -1 2 q -1 3 q -1 4 q 1 1 q 1 2 q 1 3 q 1 4 m d1 m d2 n 1 n 2 n 3 n 4 n 5 r s 1 s 2 s t0 t 0 m d1 m d2 n 1 n 2 n 3 n 4 n 5 r s 1 s 2 s t0 t 0 m d1 m d2 n 1 n 2 n 3 n 4 n 5 r s 1 s 2 s t0 t 0 m d1 m d2 n 1 n 2 n 3 n n 5 r s 1 s 2 s t0 t 0 q -1 1 q -1 2 q -1 3 q -1 4 q 1 1 q 1 2 q 1 3 q 1 4 w int w rt w x q -1 1 q -1 2 q -1 3 q -1 4 q 1 1 q 1 2 q 1 3 q 1 4 w int w rt w x q -1 1 q -1 2 q -1 3 q -1 4 q 1 1 q 1 2 q 1 3 q 1 4 w int w rt w x q -1 1 q -1 2 q -1 3 q -1 4 q 1 1 q q 1 3 q 1 4</formula><p>w int w rt w x a b n 1 n 2 n 3 n 4 n 5 s t0 t 0 a b n 1 n 2 n 3 n 4 n 5 s t0 t 0 a b n 1 n 2 n 3 n 4 n 5 s t0 t 0 a b n 1 n 2 n n 4 n 5 s t0 t 0</p><formula xml:id="formula_25">q -1 1 q -1 2 q -1 3 q -1 4 q 1 1 q 1 2 q 1 3 q 1 4 w int w rt w x q -1 1 q -1 2 q -1 3 q -1 4 q 1 1 q 1 2 q 1 3 q 1 4 w int w rt w x q -1 1 q -1 2 q -1 3 q -1 4 q 1 1 q 1 2 q 1 3 q 1 4 w int w rt w x q -1 1 q -1 2 q -1 3 q -1 4 q 1 1 q q 1 3 q 1 4</formula><p>w int w rt w x a b n 1 n 2 n 3 n 4 n 5 s t0 t 0 a b n 1 n 2 n 3 n 4 n 5 s t0 t 0 a b n 1 n 2 n 3 n 4 n 5 s t0 t 0 a b n 1 n 2 n n 4 n 5 s t0 t 0 l s Vis s Vis Concordance correlation coefficients <ref type="bibr" target="#b32">(Lin, 1989)</ref> between the true and recovered parameters from the parameter recovery across the number of trials per condition and stimulus identity (columns) and generative model (rows). Fitting times for the simulated data sets in the parameter recovery.</p><formula xml:id="formula_26">t q -1 1 q -1 2 q -1 3 q -1 4 q 1 1 q 1 2 q 1 3 q 1 4 w l s Vis s Vis t q -1 1 q -1 2 q -1 3 q -1 4 q 1 1 q 1 2 q 1 3 q 1 4 w l s Vis s Vis t q -1 1 q -1 2 q -1 3 q -1 4 q 1 1 q 1 2 q 1 3 q 1 4 w l s Vis s Vis t q -1 1 q -1 2 q -1 q -1 4 q 1 1 q 1 2 q 1 3 q 1 4 w a n</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model recovery analysis</head><p>Besides the importance of being able to robustly estimate model parameters for each individual model, it is important to be able to identify the true data generating model among a set of candidate models, given some model is reasonably close to the data generating process.</p><p>We assessed model recovery in a similar way as parameter recovery, simulating data for four of the implemented models: 2DSD, dynaViTE, IRMt, and PCRMt. We then fitted each of these four models to the artificial datasets. Based on the fits, we identified the best fitting model in terms of the PEP for the whole simulated sample using the implemented group_BMS_fit function. In addition, we classified models in terms of the minimal BIC, AIC, and AICc for individual simulations and computed the classification precision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>For the simulation of artificial data, we used the same method as in the parameter recovery analysis, sampling from parameter sets obtained by previous model fits to empirical data.</p><p>We sampled 50 parameter sets for each of the following models: 2DSD, dynaViTE, IRMt, PCRMt, and MTLNR. For each parameter set, we simulated artificial data with 100 trials per combination of stimulus identity and discriminability, resulting in 1000 trials per individual.</p><p>We then fitted each of the five models used for data generation to each of the simulated data sets.</p><p>We fitted the models using the initial grid search, the four most promising parameter sets for two iterative calls to the optimization algorithm each. We reduced the number of optimization routines to speed up the fitting. The results show, however, that model recovery is still very good.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Figure <ref type="figure">10</ref> shows the time needed to fit each data set. The race models are generally fitted faster with an expected time of 1 hour for the PCRMt and slightly less for IRMt. For 2DSD, most of the cases also take 1 hour, however values up to 2 hours occasionally occur. The longest fitting times are observed for dynaViTE-the most complex model-with up to 4 hours, while the most cases fall below 2 hours.</p><p>MTLNR shows the highest median fitting time with around 1.5 hours, despite the relatively small number of parameters. This is probably due to the high numbers of steps in the numerical integration necessary to achieve a sufficient precision in the likelihood (see Precision analysis). Note that this is the time to fit each participant if no parallelization is used within the participants. The results suggest a very good model recovery on the individual level (Fig. <ref type="figure">11</ref>, upper panel)for all models but MTLNR. Race models and DDM-based models can be clearly separated, and also among the model architectures, there is only slight confusion for individual subjects. The fitting procedure misidentifies the MTLNR with the 2DSD in 13 out of the 50 simulated data sets (26%), which indicates that there is a high risk of model mimicry between these two models. On a group-level, the PEP for each generative model was close to 1 for the whole sample of 50 data sets, with MTLNR achieving the lowest PEP with .9991 and values indistinguishable from 1 for the other models. Because experimental studies with a big number of trials often rely on smaller sample sizes, we conducted a bootstrap analysis, in which we draw 1000 sub-samples of 10 data sets for each generative model and computed PEP on each subset. This analyses is rather conservatives because studies with only 10 participants and 500 trials per participant seem rather unreliable in general when using diffusion models and non-hierarchical methods. The results indicated that the model recovery of 2DSD, dynaViTE, IRMt, and PCRMt was robust (Fig. <ref type="figure">11</ref>, lower panel). The only exception was MTLNR, which got occasionally identified incorrectly as 2DSD. Note that all selection analyses were conducted based on the BIC, which is the most conservative criterion. When using the less conservative AIC, results look similar on an individual level, but slightly better on a group-level (Appendix Figure <ref type="figure">C1</ref>) for the comparison between 2DSD and dynaViTE. The AIC is therefore preferable over the BIC when comparing these two models.</p><p>These results indicate while a comparison between diffusion-based models with race models is very robust in general both on the individual and group level, some models may show model mimicry on an individual level but also on the group level if sample size is low. Group-level comparisons are very robust for a sufficiently large sample size. In the case of small samples and small number of trials, we therefore recommend to conduct a model mimicry analysis for the fitted models using the parameter estimates for the data at hand. Fitting times for the simulated data sets in the model recovery.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Precision analysis</head><p>Two numerical approximations are involved in the computation of the probability densities. First, in the drift diffusion-based models (dynaViTE, dynWEV, 2DSD, and DDConf), the infinite series in the formula for the first-passage time density is approximated using a truncated summation for which an upper bound for the error is available <ref type="bibr" target="#b42">(Navarro &amp; Fuss, 2009)</ref>. However, the integration over the variation in starting point and the variation in the non-decision time component are not analytically solvable and thus is computed numerically. This second approximation also leads to uncertainty in the precision of the density computations. The numerical computation of the integral uses a rectangular approximation of the density with an equidistant grid of support points. The step size for this approximation is controlled by the precision argument. The value of the precision argument is transformed into step sizes using similar computations as in the rtdists package <ref type="bibr" target="#b71">(Singmann et al., 2020)</ref>. Because there are no mathematical guarantees in the form of upper error bounds, we conducted a simulation study to assess the expected error for different values of the precision arguments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>We estimated the expected error by computing the densities to simulated observations from different parameter sets several times with different values for the precision argument. Afterward, we computed the mean difference between the calculated density values as a measure of the error in the computation. Parameter sets were simulated in the following way.</p><p>Confidence judgments were assumed to be measured live on a three-point scale (i.e., K = 3), and there were three levels of stimulus discriminability (i.e., L = 3). This means that for dynaViTE, there were 11 + 3 + 2 • 2 = 18 parameters, for IRMt and PCRMt, there were 6 + 3 + 4 = 13 parameters, and for MTLNR, there were 10 + 3 + 2 • 2 = 17 parameters.</p><p>Parameters were sampled independently and uniformly, with some exceptions. First, the discriminability parameters were uniformly distributed for the first level, and the differences between discriminability levels were uniformly distributed. This ensured increasing levels of discriminability.</p><p>Second, starting point variability in dynaViTE was uniformly distributed across the admissible range dependent on the mean starting point parameter z. Similarly, the three weight parameters w X , w RT , and w Int are sampled sequentially. In addition, for the upper decision boundaries of the two processes in race models, their sum and relative height were independently uniformly distributed to more closely resemble how boundary separation and relative starting point in dynaViTE were sampled. Finally, the confidence thresholds were computed based on a simulated proportion of ratings, which ensured a minimum number of observations in each category.</p><p>We derived parameter ranges from previously conducted model fits to empirical data from <ref type="bibr" target="#b20">Hellmann et al. (2023</ref><ref type="bibr" target="#b21">Hellmann et al. ( , 2024))</ref>, and the example in this paper.</p><p>We sampled 50 random parameter sets per model for dynaViTE, IRMt, PCRMt, and MTLNR. A data set with 50 trials for each combination of discriminability condition and stimulus category was generated for each parameter set (600 trials per data set in total). Finally, we computed the trial-wise likelihood for the simulated data with different precision arguments. For dynaViTE and MTLNR, we used values from 2 to 8 in steps of 0.5 plus a value of 9. For the race models, we used values from 2 to 7 in steps of 0.5 plus a precision of 9. The probabilities attained with the highest precision, i.e., 9, were used as references for the other precision values. To estimate the absolute error, we computed the mean absolute distance between the probabilities for each precision to the reference. In addition, we computed the mean absolute difference between two consecutive precision values to estimate the expected improvement of the density calculation. For full details, we refer the reader to the analysis code.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>The mean absolute differences for the computed probability densities between different values of precision arguments are depicted for dynaViTE in Figure <ref type="figure" target="#fig_1">12</ref>, for the race models in Figure <ref type="figure">13</ref>, and for MTLNR in Figure <ref type="figure">14</ref>. For all models, the estimated error and the difference between subsequent values of the precision argument both start far below the required value for low precision values and then decrease exponentially as functions of the precision argument for higher values. Assuming that the exponential decrease of subsequent differences continues, we can infer that the magnitude of the error in the computed densities is proportional to the estimated error in our simulation. This means that with the default value of 6 for the precision argument in the densities, the expected absolute error is about 10 -6 of magnitude, while for a value of 7.5, it is 10 -7.5 . In general, the transformation between the precision argument and the step size used for the numerical integration is chosen such that the provided precision represents the number of digits correctly calculated on average. Notably, the computation time for the probability densities also increases exponentially with the precision argument <ref type="bibr">lower rows)</ref>, which clarifies the trade-off between precision and computation time. Because only one numerical integration is necessary for race models -IRMt, PCRMt, and MTLNR do not include between-trial variability in starting points -the computation time should be expected to be less influenced by the precision. While we see a lower intercept and slope for IRMt and PCRMt, i.e., faster computations, the computation time for MTLNR is similar to the dynaViTE, suggesting that the step-size required for obtaining a required precision is much smaller compared to the other models.  IRMt PCRMt 10 -7 10 -5 10 -3 10 -1 Mean absolute difference between precision and (precision+0.5) 10 -7 10 -5 10 -3 10 -1</p><p>Mean absolute difference between precision and (precision=9) 2 2.5 3 3.5 4 4.5 5 5.5 6 6.5 7 9 2 2.5 3 3.5 4 4.5 5 5.5 6 6. First Row: Distribution of mean absolute differences in computed densities between consecutive increases in the exponent of the precision argument. Second Row: Distribution of mean absolute differences in computed densities between different choices of the precision argument and the computed densities for precision = 9.</p><p>Third Row: Distribution of computation time of the densities for a vector of 600 observations (log scaled).</p><p>Each observation is based on 600 simulated trials for a random parameter set (50 trials for each combination of discriminability condition and stimulus category).</p><p>10 -7 10 -5 10 -3 10 -1 2 2.5 3 3.5 4 4.5 5 5.5 6 6.5 7 7.5 8 9 Mean absolute difference between precision and (precision+0.5) 10 -7 10 -5 10 -3 10 -1 Mean absolute difference between precision and (precision=9) 10 -1 10 0 10 1 10 2 10 3 10 4 2 2.5 3 3.5 4 4.5 5 5.5 6 6.5 7 7.5 8 9 Precision argument Computation time [sec]</p><p>Default for density Default for fitting</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 14</head><p>First Row: Distribution of mean absolute differences in computed densities between consecutive increases in the exponent of the precision argument. Second Row: Distribution of mean absolute differences in computed densities between different choices of the precision argument and the computed densities for precision = 9.</p><p>Third Row: Distribution of computation time of the densities for a vector of 600 observations (log scaled).</p><p>Each observation is based on 600 simulated trials for a random parameter set (50 trials for each combination of discriminability condition and stimulus category).</p><p>Leftward motion Rightward motion PCRMt IRMt dynaViTE dynWEV 2DSD MTLNR 1 2 3 4 5 1 2 3 4 5 2.0 2.4 2.8 2.0 2.4 2.8 2.0 2.4 2.8 2.0 2.4 2.8 2.0 2.4 2.8 2.0 2.4 2.8 Motion coherence level Mean confidence rating Observed Correct Wrong Predicted Correct Wrong dynaViTE (fixed) dynaViTE dynWEV (fixed) dynWEV 2DSD (fixed) 2DSD 0.6 0.7 0.8 Mean Accuracy Observed Predicted 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 2.0 2.3 2.6 Motion coherence level Mean confidence rating Observed Correct Wrong Predicted Correct Wrong Figure A3 Accuracy (top row) and mean confidence rating (bottom row) for empirical data (points and triangles) and model predictions from the full and restricted DDM-based models (lines). Error bars represent within-subject standard errors.</p><p>Wrong Correct dynaViTE (fixed) dynaViTE dynWEV (fixed) dynWEV 2DSD (fixed) 2DSD 1 2 3 4 5 1 2 3 4 5 0.14 0.30 0.65 1.40 0.14 0.30 0.65 1.40 0.14 0.30 0.65 1.40 0.14 0.30 0.65 1.40 0.14 0.30 0.65 1.40 0.14 0.30 0.65 1.40 Motion coherence level Reaction time quantiles [s] (log scaled) Observed Correct Wrong Predicted Correct Wrong</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure A4</head><p>Response time quantiles for observed (points) and predicted (lines) response time distributions across correct and incorrect decisions (columns) and levels of stimulus discriminability (x-axis). Probabilities for quantiles: .1, .5, .9.</p><p>Wrong Correct dynaViTE (fixed) dynaViTE dynWEV (fixed) dynWEV 2DSD (fixed) 2DSD 1 2 3 4 1 2 3 4 0.10 0.25 0.60 1.50 0.10 0.25 0.60 1.50 0.10 0.25 0.60 1.50 0.10 0.25 0.60 1.50 0.10 0.25 0.60 1.50 0.10 0.25 0.60 1.50 Confidence rating Reaction time quantiles [s] (log scaled) Observed Correct Wrong Predicted Correct Wrong</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure A5</head><p>Response time quantiles for observed (points) and predicted (lines) response time distributions across correct and incorrect decisions (columns) and confidence ratings (x-axis). Probabilities for quantiles: .1, .5, .9.</p><p>We then drew random probability vectors from the Dirichlet distribution as proportions of confidence reports, resampling if any proportion was less than 2%. The confidence thresholds were then computed as quantiles of the confidence variable in the simulated data set. This procedure ensured that each confidence level contained a non-zero proportion of responses.</p><p>To assess the number of trials necessary to recover the parameters, we sampled either 50, 100, 200, or 500 trials per condition and stimulus identity. For two stimulus identities and five levels of discriminability, this leads to 500, 1,000, 2,000, and 5,000 trials per simulated data set for five discriminability conditions.</p><p>For each number of artificial trials, we sampled 100 parameter sets and generated one data set per parameter set.</p><p>To measure parameter recovery performance, we computed the concordance correlation coefficient (CCC; <ref type="bibr" target="#b32">Lin, 1989)</ref>, which, in contrast to Pearson correlation, is reduced by non-zero intercepts and non-unit slopes. Therefore, in contrast to Pearson's correlation coefficient, it is sensitive to deviations from the identity line.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recovery Plots</head><p>0.06 0.2 q 1 3 q 1 4 w z q -1 3 q -1 4 q 1 1 q 1 2 t 0 t q -1 1 q -1 2 s t0 s Vis s z s Vis q 1 3 q 1 4 w z q -1 3 q -1 4 q 1 1 q 1 2 t 0 t q -1 1 q -1 2 s t0 s Vis s z s Vis q 1 4 w int w rt w x q -1 4 q 1 1 q 1 2 q 1 3 t 0 q -1 1 q -1 2 q -1 3 q 1 4 w int w rt w x q -1 4 q 1 1 q 1 2 q 1 3 t 0 q -1 1 q -1 2 q -1 3 q 1 4 w int w rt w x q -1 4 q 1 1 q 1 2 q 1 3 t 0 q -1 1 q -1 2 q -1 3 q 1 4 w int w rt w x q -1 4 q 1 1 q 1 2 q 1 3 t 0 q -1 1 q -1 2 q -1 3 q 1 4 w int w rt w x q -1 4 q 1 1 q 1 2 q 1 3 t 0 q -1 1 q -1 2 q -1 3 q 1 1 q 1 2 q 1 3 q 1 4 q -1 1 q -1 2 q -1 3 q -1 4 q 1 1 q 1 2 q 1 3 q 1 4 q -1 1 q -1 2 q -1 3 q -1 4 q 1 1 q 1 2 q 1 3 q 1 4 q -1 1 q -1 2 q -1 3 q -1 4 q 1 1 q 1 2 q 1 3 q 1 4 q -1 1 q -1 2 q -1 3 q -1 4 </p><formula xml:id="formula_27">q 1 3 q 1 4 w z q -1 3 q -1 4 q 1 1 q 1 2 t 0 t q -1 1 q -1 2 s t0 s Vis s z s Vis n 3 n 4 n 5 s n a l n 1 n 2 1 2<label>3</label></formula><formula xml:id="formula_28">q 1 3 q 1 4 w z q -1 3 q -1 4 q 1 1 q 1 2 t 0 t q -1 1 q -1 2 s t0 s Vis s z s Vis n 3 n 4 n 5 s n a l n 1 n 2 1 2<label>3</label></formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Introduction</head><figDesc>Alternative software . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2</head><label>2</label><figDesc>Figure 2 Upper panel: BIC weights across participants (reordered). Middle panel: Negative mean BIC values. Error bars represent within-subject standard errors. Lower panel: Results from a Bayesian model selection analysis. Violin plots show simulated model probabilities from a Dirichlet distribution fitted to BIC values according to a random effects model. Solid bars indicate the corresponding protected exceedance probability, dotted bars indicate the model probabilities resulting from a fixed effect model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><figDesc>Figure 3Observed (bars) and predicted (points) response distribution for the different models (shape and color of points) across stimulus identity (columns, high level) and levels of stimulus discriminability (rows).Probabilities within each row and stimulus identity column add to 1 for each group of data shown, i.e., height represents the conditional probability of a given accuracy and confidence rating given the stimulus discriminability and identity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 7</head><label>7</label><figDesc>Figure 7 Upper panel: BIC weights across participants (reordered). Middle panel: Negative mean BIC values. Error bars represent within-subject standard errors. Lower panel: Results from a Bayesian model selection analysis. Violin plots show simulated model probabilities from a Dirichlet distribution fitted to BIC values according to a random effects model. Solid bars indicate the corresponding protected exceedance probability, dotted bars indicate the model probabilities resulting from a fixed effect model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><figDesc>Figure 8</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><figDesc>Figure 9</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><figDesc>Figure 10</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><figDesc>Figure 11Upper panel: Individual model weights for each generative model (rows) across simulated participants.Lower panel: Bootstrapped protected exceedance probabilities (PEP).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><figDesc>Figure 12First Row: Distribution of mean absolute differences in computed densities between different choices of the precision argument and the argument +0.5. Second Row: Distribution of mean absolute differences in computed densities between different choices of the precision argument and the computed densities for precision = 8.5. Third Row: Distribution of computation time of the densities for a vector of 600 observations (log scaled). Each observation is based on 600 simulated trials for a random parameter set (50 trials for each combination of discriminability condition and stimulus category).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><figDesc>Figure13</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure A2 Observed</head><label>A2</label><figDesc>Figure A2Observed (points) and fitted (lines) mean confidence judgments by accuracy (line color, shape) and different responses (columns). Error bars represent within-subject standard errors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><figDesc>Figure B1 Recovered vs. true generative parameters across parameters. Each point represents one simulated parameter and data set. The blue line and shaded area show a linear regression line with 95% confidence band. The grey line shows the identity line. Numbers in the panels show the concordance correlation coefficient for the parameter.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><figDesc>Figure B2 Recovered vs. true generative parameters across parameters. Each point represents one simulated parameter and data set. The blue line and shaded area show a linear regression line with 95% confidence band. The grey line shows the identity line. Numbers in the panels show the concordance correlation coefficient for the parameter.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><figDesc>Figure B3 Recovered vs. true generative parameters across parameters. Each point represents one simulated parameter and data set. The blue line and shaded area show a linear regression line with 95% confidence band. The grey line shows the identity line. Numbers in the panels show the concordance correlation coefficient for the parameter.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><figDesc>Figure B4 Recovered vs. true generative parameters across parameters. Each point represents one simulated parameter and data set. The blue line and shaded area show a linear regression line with 95% confidence band. The grey line shows the identity line. Numbers in the panels show the concordance correlation coefficient for the parameter.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><figDesc>Figure B5 Recovered vs. true generative parameters across parameters. Each point represents one simulated parameter and data set. The blue line and shaded area show a linear regression line with 95% confidence band. The grey line shows the identity line. Numbers in the panels show the concordance correlation coefficient for the parameter.</figDesc><graphic coords="75,101.47,517.42,89.71,64.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><figDesc>Figure B6 Recovered vs. true generative parameters across parameters. Each point represents one simulated parameter and data set. The blue line and shaded area show a linear regression line with 95% confidence band. The grey line shows the identity line. Numbers in the panels show the concordance correlation coefficient for the parameter.</figDesc><graphic coords="76,101.47,517.42,89.71,64.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><figDesc>Figure B7 Recovered vs. true generative parameters across parameters. Each point represents one simulated parameter and data set. The blue line and shaded area show a linear regression line with 95% confidence band. The grey line shows the identity line. Numbers in the panels show the concordance correlation coefficient for the parameter.</figDesc><graphic coords="77,101.47,517.42,88.79,64.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><figDesc>Figure B8 Recovered vs. true generative parameters across parameters. Each point represents one simulated parameter and data set. The blue line and shaded area show a linear regression line with 95% confidence band. The grey line shows the identity line. Numbers in the panels show the concordance correlation coefficient for the parameter.</figDesc><graphic coords="78,101.47,517.42,87.88,64.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><figDesc>Figure B9 Recovered vs. true generative parameters across parameters. Each point represents one simulated parameter and data set. The blue line and shaded area show a linear regression line with 95% confidence band. The grey line shows the identity line. Numbers in the panels show the concordance correlation coefficient for the parameter.</figDesc><graphic coords="79,101.47,517.42,88.79,64.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><figDesc>Figure B13 Recovered vs. true generative parameters across parameters. Each point represents one simulated parameter and data set. The blue line and shaded area show a linear regression line with 95% confidence band. The grey line shows the identity line. Numbers in the panels show the concordance correlation coefficient for the parameter.</figDesc><graphic coords="83,98.61,517.42,88.79,64.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><figDesc>Figure B14 Recovered vs. true generative parameters across parameters. Each point represents one simulated parameter and data set. The blue line and shaded area show a linear regression line with 95% confidence band. The grey line shows the identity line. Numbers in the panels show the concordance correlation coefficient for the parameter.</figDesc><graphic coords="84,98.61,517.42,89.71,64.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><figDesc>Figure B15 Recovered vs. true generative parameters across parameters. Each point represents one simulated parameter and data set. The blue line and shaded area show a linear regression line with 95% confidence band. The grey line shows the identity line. Numbers in the panels show the concordance correlation coefficient for the parameter.</figDesc><graphic coords="85,98.61,517.42,90.63,64.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><figDesc>Figure B16 Recovered vs. true generative parameters across parameters. Each point represents one simulated parameter and data set. The blue line and shaded area show a linear regression line with 95% confidence band. The grey line shows the identity line. Numbers in the panels show the concordance correlation coefficient for the parameter.</figDesc><graphic coords="86,104.33,517.42,89.71,64.99" type="bitmap" /></figure>
		</body>
		<back>

			<div type="funding">
<div><head>Funding</head><p>This work was funded by the <rs type="funder">Deutsche Forschungsgemeinschaft</rs> (grant numbers <rs type="grantNumber">ZE887/8-1</rs> to MZ and <rs type="grantNumber">RA2988/3-1</rs> to MR).</p></div>
<div><head>Funding</head><p>This work was partly funded by the <rs type="funder">Deutsche Forschungsgemeinschaft</rs> (grants <rs type="grantNumber">ZE887/8-1</rs>, <rs type="grantNumber">ZE887/9-1</rs> to MZ and <rs type="grantNumber">RA2988/3-1</rs>, <rs type="grantNumber">RA2988/4-1</rs> to MR).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_yz2KcF9">
					<idno type="grant-number">ZE887/8-1</idno>
				</org>
				<org type="funding" xml:id="_3Rs93gX">
					<idno type="grant-number">RA2988/3-1</idno>
				</org>
				<org type="funding" xml:id="_2zUVZkU">
					<idno type="grant-number">ZE887/8-1</idno>
				</org>
				<org type="funding" xml:id="_uMnCmKV">
					<idno type="grant-number">ZE887/9-1</idno>
				</org>
				<org type="funding" xml:id="_tpMSGR5">
					<idno type="grant-number">RA2988/3-1</idno>
				</org>
				<org type="funding" xml:id="_kpEjMtA">
					<idno type="grant-number">RA2988/4-1</idno>
				</org>
			</listOrg>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The dynConfiR package is available on CRAN (<ref type="url" target="https://cran.r-project.org/web/packages/dynConfiR/">https://cran.r-project.org/web/packages/dynConfiR/</ref>). This paper is based on version 1.1.1 of the package. Data and code for this paper are available at <ref type="url" target="https://github.com/SeHellmann/dynConfiR_Paper">https://github.com/SeHellmann/dynConfiR_Paper</ref>.</p><p>The development version of the package is available at <ref type="url" target="https://github.com/SeHellmann/dynConfiR">https://github.com/SeHellmann/</ref></p></div>
			</div>


			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Availability of data and materials</head><p>Data sets are available for download at <ref type="url" target="https://github.com/SeHellmann/dynConfiR_Paper">https://github.com/SeHellmann/dynConfiR_Paper</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Code availability</head><p>Code for all analyses and production of figures is available for download at <ref type="url" target="https://github.com/SeHellmann/dynConfiR_Paper">https://github.com/SeHellmann/dynConfiR_Paper</ref>.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Competing interests</head><p>The authors have no relevant financial or non-financial interests to disclose.</p><p>Fitting the parameters to experimental data using the default arguments for the fitting function may require up to 140,000 evaluations of the negative log-likelihood of the data (around 12,000 parameter sets in the initial grid search) plus 125,000 evaluations from the optimization (5 starting parameter sets each with five calls of the optimization routine each with a maximum of 5,000 function evaluations per optimization call). Keeping the computation time low is essential for the applicability of these models (see Figure <ref type="figure">9</ref>). Therefore, we use a default precision of 3 in the fitting functions. Evaluating the likelihood with 600 trials takes much less than a second. Still, the results from the recovery analyses show that this is sufficient to produce a high model and parameter recovery.</p><p>In addition, using the default values, the precision of parameter estimates and likelihoods is often limited by other factors like the timing of stimulus presentation and the measurement precision of reaction times. For experimental response time data, the precision of reaction time measurements is often limited to milliseconds, and the precision depends on the hardware and the software used to conduct the experiment <ref type="bibr" target="#b6">(Bridges et al., 2020;</ref><ref type="bibr" target="#b47">Plant &amp; Turner, 2009)</ref>. For online studies, the precision is often lower <ref type="bibr" target="#b4">(Anwyl-Irvine et al., 2021;</ref><ref type="bibr" target="#b68">Semmelmann &amp; Weigelt, 2017)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Summary</head><p>The dynConfiR package implements state-of-the-art computational models of choice, response time, and decision confidence based on the drift diffusion model and race models of choice. The R package may prove to be an attractive tool for psychology and cognitive neuroscience researchers because it offers a user-friendly implementation of the probability distributions of observed data and functions for parameter fitting, prediction, and simulation. The package is freely available via the CRAN repository, which provides sustainable access and facilitates its installation for the user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contributions and bug reports</head><p>Any issue and observed bugs in the package may be reported here: <ref type="url" target="https://github.com/SeHellmann/dynConfiR/issues">https://github.com/SeHellmann/dynConfiR/issues</ref>. Finally, we encourage any contributions in the form of additional implemented models or extensions of the package functionalities in the form of pull requests. A brief instruction on how to contribute new models is available at <ref type="url" target="https://github.com/SeHellmann/dynConfiR/">https://github.com/SeHellmann/dynConfiR/</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Declarations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Competing interests</head><p>The authors have no relevant financial or non-financial interests to disclose.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ethics approval</head><p>Not applicable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Consent to participate</head><p>Not applicable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Consent for publication</head><p>Not applicable. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Authors' contributions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B Parameter Recovery</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Detailed Method</head><p>For measuring parameter recovery, we generated artificial data sets from a known set of model parameters, fitted the model to the synthetic data, and compared the recovered parameters to the generating parameters.</p><p>We assumed that there were five levels of confidence (i.e., K = 5), and there were five levels of stimulus discriminability (i.e., L = 5). This means that for dynaViTE, there were 11 + 5 + 2 • 5 = 26 fitted parameters, for IRMt and PCRMt, there were 6 + 5 + 10 = 21 parameters, and for MTLRN, there were 7 + 5 + 10 = 22 parameters.</p><p>The generating parameter sets (except for the confidence thresholds) were sampled from parameters derived from previously conducted model fits to empirical data.</p><p>We gathered parameter sets from <ref type="bibr" target="#b20">Hellmann et al. (2023</ref><ref type="bibr" target="#b21">Hellmann et al. ( , 2024))</ref>, and the example in this paper. For all four models we used the estimates to the data from <ref type="bibr" target="#b20">Hellmann et al. (2023)</ref> and the estimates to the data from Law and Lee <ref type="bibr" target="#b44">(Ng et al., 2021)</ref>. In addition, dynaViTE, PCRMt, and MTLNR were additionally fitted to the data from Shekhar and Rahnev (2021, see the example in this article). Finally, for MTLNR, we also used estimates to the data from Experiment 2 in <ref type="bibr" target="#b45">Orchard et al. (2022)</ref>. In total, this resulted in 93 parameter sets for dynaViTE and PCRMt, 73 parameter sets for IRMt, and 110 parameter sets for MTLNR. For the 20 parameter sets fitted to the data of <ref type="bibr" target="#b69">Shekhar and Rahnev (2021)</ref>, which had only three experimental conditions, the means of the estimated drift rates from two consecutive conditions were used as additional experimental conditions (i.e. the fitted drift rates (ν 1 , ν 2 , ν 3 ) were mapped to (ν 1 , (ν 1 + ν 2 )/2, ν 2 , (ν 2 + ν 3 )/2ν 3 )). For the estimates to the data from <ref type="bibr" target="#b45">Orchard et al. (2022)</ref>, which had eight difficulty levels, we used the sensitivity parameters of the third and sixth level as sensitivity parameters for the second and fourth level in the simulation. In addition, we computed the average of the first and second, the fourth and fifth, and the seventh and eighth level for the first, third, and fifth level in the simulation, respectively. For more details, see the accompanying code.</p><p>Concerning the confidence thresholds, we opted not to utilize the thresholds from the previous model fits. The reason for not using the fitted confidence thresholds was that some participants did not use all confidence categories, resulting in some thresholds being either fitted to plus or minus infinity or coinciding with one another. In contrast, we used the fact that when simulating artificial data, we can simulate the continuous confidence variable in the model and compute the confidence thresholds as quantiles of the confidence variable, given the proportions of confidence ratings. We fitted a Dirichlet distribution to the observed proportions of confidence ratings from the empirical data of all participants.</p><p>q 1 4 w int w rt w x q -1 4 q 1 1 q 1 2 q 1 3 t 0 q -1 1 q -1 2 q -1 3 q 1 4 w int w rt w x q -1 4 q 1 1 q 1 2 q 1 3 t 0 q -1 1 q -1 2 q -1 3 q 1 4 w int w rt w x q -1 4 q 1 1 q 1 2 q 1 3 t 0 q -1 1 q -1 2 q -1 3 </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Comparing bayesian and non-bayesian accounts of human confidence reports</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Adler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Ma</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pcbi.1006572</idno>
		<ptr target="https://doi.org/10.1371/journal.pcbi.1006572" />
	</analytic>
	<monogr>
		<title level="j">PLoS computational biology</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">1006572</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Adler, W. T., &amp; Ma, W. J. (2018). Comparing bayesian and non-bayesian accounts of human confidence reports. PLoS computational biology, 14 (11), Article e1006572. https://doi.org/10.1371/journal.pcbi.1006572</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Doubly bayesian analysis of confidence in perceptual decision-making</title>
		<author>
			<persName><forename type="first">L</forename><surname>Aitchison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bahrami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Latham</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pcbi.1004519</idno>
		<ptr target="https://doi.org/10.1371/journal.pcbi.1004519" />
	</analytic>
	<monogr>
		<title level="j">PLOS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">1004519</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Aitchison, L., Bang, D., Bahrami, B., &amp; Latham, P. E. (2015). Doubly bayesian analysis of confidence in perceptual decision-making. PLOS Computational Biology, 11 (10), Article e1004519. https://doi.org/10.1371/journal.pcbi.1004519</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A new look at the statistical model identification</title>
		<author>
			<persName><forename type="first">H</forename><surname>Akaike</surname></persName>
		</author>
		<idno type="DOI">10.1109/TAC.1974.1100705</idno>
		<ptr target="https://doi.org/10.1109/TAC.1974.1100705" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Automatic Control</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="716" to="723" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Akaike, H. (1974). A new look at the statistical model identification. IEEE Transactions on Automatic Control, 19 (6), 716-723. https://doi.org/10.1109/TAC.1974.1100705</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Fast-dm: A free program for efficient diffusion model analysis</title>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jochen</forename><surname>Voss</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03192967</idno>
		<ptr target="https://doi.org/10.3758/BF03192967" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="767" to="775" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Andreas Voss &amp; Jochen Voss. (2007). Fast-dm: A free program for efficient diffusion model analysis. Behavior Research Methods, 39 (4), 767-775. https://doi.org/10.3758/BF03192967</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Realistic precision and accuracy of online experiment platforms, web browsers, and devices</title>
		<author>
			<persName><forename type="first">A</forename><surname>Anwyl-Irvine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Dalmaijer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hodges</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Evershed</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13428-020-01501-5</idno>
		<ptr target="https://doi.org/10.3758/s13428-020-01501-5" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1407" to="1425" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Anwyl-Irvine, A., Dalmaijer, E. S., Hodges, N., &amp; Evershed, J. K. (2021). Realistic precision and accuracy of online experiment platforms, web browsers, and devices. Behavior Research Methods, 53 (4), 1407-1425. https://doi.org/10.3758/s13428-020-01501-5</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The physics of optimal decision making: A formal analysis of models of performance in two-alternative forced-choice tasks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bogacz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Moehlis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-295X.113.4.700</idno>
		<ptr target="https://doi.org/10.1037/0033-295X.113.4.700" />
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="700" to="765" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Bogacz, R., Brown, E., Moehlis, J., Holmes, P., &amp; Cohen, J. D. (2006). The physics of optimal decision making: A formal analysis of models of performance in two-alternative forced-choice tasks. Psychological review, 113 (4), 700-765. https://doi.org/10.1037/0033-295X.113.4.700</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The timing mega-study: Comparing a range of experiment generators, both lab-based and online</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bridges</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pitiot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Macaskill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Peirce</surname></persName>
		</author>
		<idno type="DOI">10.7717/peerj.9414</idno>
		<ptr target="https://doi.org/10.7717/peerj.9414" />
	</analytic>
	<monogr>
		<title level="j">PeerJ</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<date type="published" when="2020">2020. 9414</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Bridges, D., Pitiot, A., MacAskill, M. R., &amp; Peirce, J. W. (2020). The timing mega-study: Comparing a range of experiment generators, both lab-based and online. PeerJ, 8, e9414. https://doi.org/10.7717/peerj.9414</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A ballistic model of choice response time</title>
		<author>
			<persName><forename type="first">S</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Heathcote</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-295X.112.1.117</idno>
		<ptr target="https://doi.org/10.1037/0033-295X.112.1.117" />
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="117" to="128" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Brown, S., &amp; Heathcote, A. (2005). A ballistic model of choice response time. Psychological review, 112 (1), 117-128. https://doi.org/10.1037/0033-295X.112.1.117</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The simplest complete model of choice response time: Linear ballistic accumulation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Heathcote</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cogpsych.2007.12.002</idno>
		<ptr target="https://doi.org/10.1016/j.cogpsych.2007.12.002" />
	</analytic>
	<monogr>
		<title level="j">Cognitive psychology</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Brown, S., &amp; Heathcote, A. (2008). The simplest complete model of choice response time: Linear ballistic accumulation. Cognitive psychology, 57 (3). https://doi.org/10.1016/j.cogpsych.2007.12.002</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Vba: A probabilistic treatment of nonlinear models for neurobiological and behavioural data</title>
		<author>
			<persName><forename type="first">J</forename><surname>Daunizeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Rigoux</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pcbi.1003441</idno>
		<ptr target="https://doi.org/10.1371/journal.pcbi.1003441" />
	</analytic>
	<monogr>
		<title level="j">PLOS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1003441</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Daunizeau, J., Adam, V., &amp; Rigoux, L. (2014). Vba: A probabilistic treatment of nonlinear models for neurobiological and behavioural data. PLOS Computational Biology, 10 (1), e1003441. https://doi.org/10.1371/journal.pcbi.1003441</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Confidence predicts speed-accuracy tradeoff for subsequent decisions</title>
		<author>
			<persName><forename type="first">K</forename><surname>Desender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Boldt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Verguts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Donner</surname></persName>
		</author>
		<ptr target="https://elifesciences.org/articles/43499" />
	</analytic>
	<monogr>
		<title level="j">eLife</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<date type="published" when="2019-12-14">2019. December 14, 2022</date>
		</imprint>
	</monogr>
	<note>Article e43499</note>
	<note type="raw_reference">Desender, K., Boldt, A., Verguts, T., &amp; Donner, T. H. (2019). Confidence predicts speed-accuracy tradeoff for subsequent decisions. eLife, 8, Article e43499. Retrieved December 14, 2022, from https://elifesciences.org/articles/43499</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Dynamic expressions of confidence within an evidence accumulation framework</title>
		<author>
			<persName><forename type="first">K</forename><surname>Desender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Donner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Verguts</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2020.104522</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2020.104522" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">207</biblScope>
			<biblScope unit="page">104522</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Desender, K., Donner, T. H., &amp; Verguts, T. (2021). Dynamic expressions of confidence within an evidence accumulation framework. Cognition, 207, Article 104522. https://doi.org/10.1016/j.cognition.2020.104522</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Dynamic influences on static measures of metacognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>Desender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vermeylen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Verguts</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41467-022-31727-0</idno>
		<ptr target="https://doi.org/10.1038/s41467-022-31727-0" />
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">4208</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Desender, K., Vermeylen, L., &amp; Verguts, T. (2022). Dynamic influences on static measures of metacognition. Nature Communications, 13 (1), 4208. https://doi.org/10.1038/s41467-022-31727-0</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning optimal decisions with confidence</title>
		<author>
			<persName><forename type="first">J</forename><surname>Drugowitsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Mendonça</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">F</forename><surname>Mainen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pouget</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.1906787116</idno>
		<ptr target="https://doi.org/10.1073/pnas.1906787116" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences of the United States of America</title>
		<imprint>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="issue">49</biblScope>
			<biblScope unit="page" from="24872" to="24880" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Drugowitsch, J., Mendonça, A. G., Mainen, Z. F., &amp; Pouget, A. (2019). Learning optimal decisions with confidence. Proceedings of the National Academy of Sciences of the United States of America, 116 (49), 24872-24880. https://doi.org/10.1073/pnas.1906787116</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The cost of accumulating evidence in perceptual decision making</title>
		<author>
			<persName><forename type="first">J</forename><surname>Drugowitsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Moreno-Bote</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Churchland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Shadlen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pouget</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.4010-11.2012</idno>
		<ptr target="https://doi.org/10.1523/JNEUROSCI.4010-11.2012" />
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3612" to="3628" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Drugowitsch, J., Moreno-Bote, R., Churchland, A. K., Shadlen, M. N., &amp; Pouget, A. (2012). The cost of accumulating evidence in perceptual decision making. Journal of Neuroscience, 32 (11), 3612-3628. https://doi.org/10.1523/JNEUROSCI.4010-11.2012</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Computational modeling of cognition and behavior</title>
		<author>
			<persName><forename type="first">S</forename><surname>Farrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lewandowsky</surname></persName>
		</author>
		<idno type="DOI">10.1017/9781316272503</idno>
		<ptr target="https://doi.org/10.1017/9781316272503" />
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Farrell, S., &amp; Lewandowsky, S. (2018). Computational modeling of cognition and behavior. Cambridge University Press. https://doi.org/10.1017/9781316272503</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A reinforcement learning diffusion decision model for value-based decisions</title>
		<author>
			<persName><forename type="first">L</forename><surname>Fontanesi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gluth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Spektor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rieskamp</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13423-018-1554-2</idno>
		<ptr target="https://doi.org/10.3758/s13423-018-1554-2" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1099" to="1121" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Fontanesi, L., Gluth, S., Spektor, M. S., &amp; Rieskamp, J. (2019). A reinforcement learning diffusion decision model for value-based decisions. Psychonomic Bulletin &amp; Review, 26 (4), 1099-1121. https://doi.org/10.3758/s13423-018-1554-2</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Swets</surname></persName>
		</author>
		<ptr target="https://books.google.de/books?id=E-04zQEACAAJ" />
		<title level="m">Signal detection theory and psychophysics</title>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1966">1966</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Green, D. M., &amp; Swets, J. A. (1966). Signal detection theory and psychophysics. Wiley. https://books.google.de/books?id=E-04zQEACAAJ</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Reverse engineering of metacognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Guggenmos</surname></persName>
		</author>
		<idno type="DOI">10.7554/eLife.75420</idno>
		<ptr target="https://doi.org/10.7554/eLife.75420" />
	</analytic>
	<monogr>
		<title level="j">eLife</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>Article e75420</note>
	<note type="raw_reference">Guggenmos, M. (2022). Reverse engineering of metacognition. eLife, 11, Article e75420. https://doi.org/10.7554/eLife.75420</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Dynamic models of choice</title>
		<author>
			<persName><forename type="first">A</forename><surname>Heathcote</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Strickland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Matzke</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13428-018-1067-y</idno>
		<ptr target="https://doi.org/10.3758/s13428-018-1067-y" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="961" to="985" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Heathcote, A., Lin, Y.-S., Reynolds, A., Strickland, L., Gretton, M., &amp; Matzke, D. (2019). Dynamic models of choice. Behavior Research Methods, 51 (2), 961-985. https://doi.org/10.3758/s13428-018-1067-y</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Simultaneous modeling of choice, confidence, and response time in visual perception</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hellmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zehetleitner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rausch</surname></persName>
		</author>
		<idno type="DOI">10.1037/rev0000411</idno>
		<ptr target="https://doi.org/10.1037/rev0000411" />
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Hellmann, S., Zehetleitner, M., &amp; Rausch, M. (2023). Simultaneous modeling of choice, confidence, and response time in visual perception. Psychological review. https://doi.org/10.1037/rev0000411</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Confidence is influenced by evidence accumulation time in dynamical decision models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hellmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zehetleitner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rausch</surname></persName>
		</author>
		<idno type="DOI">10.1007/s42113-024-00205-9</idno>
		<ptr target="https://doi.org/10.1007/s42113-024-00205-9" />
	</analytic>
	<monogr>
		<title level="j">Computational Brain &amp; Behavior</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="287" to="313" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Hellmann, S., Zehetleitner, M., &amp; Rausch, M. (2024). Confidence is influenced by evidence accumulation time in dynamical decision models. Computational Brain &amp; Behavior, 7 (3), 287-313. https://doi.org/10.1007/s42113-024-00205-9</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The seven-parameter diffusion model: An implementation in stan for bayesian analyses</title>
		<author>
			<persName><forename type="first">F</forename><surname>Henrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hartmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Pratz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Klauer</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13428-023-02179-1</idno>
		<ptr target="https://doi.org/10.3758/s13428-023-02179-1" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="3102" to="3116" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Henrich, F., Hartmann, R., Pratz, V., Voss, A., &amp; Klauer, K. C. (2024). The seven-parameter diffusion model: An implementation in stan for bayesian analyses. Behavior Research Methods, 56 (4), 3102-3116. https://doi.org/10.3758/s13428-023-02179-1</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Modelling speed-accuracy tradeoffs in the stopping rule for confidence judgments</title>
		<author>
			<persName><forename type="first">S</forename><surname>Herregods</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Le Denmat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vermeylen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Desender</surname></persName>
		</author>
		<idno type="DOI">10.1101/2023.02.27.530208</idno>
		<ptr target="https://doi.org/10.1101/2023.02.27.530208" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Herregods, S., Le Denmat, P., Vermeylen, L., &amp; Desender, K. (2023). Modelling speed-accuracy tradeoffs in the stopping rule for confidence judgments. https://doi.org/10.1101/2023.02.27.530208</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Choice certainty is informed by both evidence and decision time</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kiani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Corthell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Shadlen</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2014.12.015</idno>
		<ptr target="https://doi.org/10.1016/j.neuron.2014.12.015" />
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1329" to="1342" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kiani, R., Corthell, L., &amp; Shadlen, M. N. (2014). Choice certainty is informed by both evidence and decision time. Neuron, 84 (6), 1329-1342. https://doi.org/10.1016/j.neuron.2014.12.015</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Wahrscheinlichkeitstheorie</title>
		<author>
			<persName><forename type="first">A</forename><surname>Klenke</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-36018-3</idno>
		<ptr target="https://doi.org/10.1007/978-3-642-36018-3" />
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin Heidelberg</pubPlace>
		</imprint>
	</monogr>
	<note type="raw_reference">Klenke, A. (2013). Wahrscheinlichkeitstheorie. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-642-36018-3</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Visual fixations and the computation and comparison of value in simple choice</title>
		<author>
			<persName><forename type="first">I</forename><surname>Krajbich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Armel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rangel</surname></persName>
		</author>
		<idno type="DOI">10.1038/nn.2635</idno>
		<ptr target="https://doi.org/10.1038/nn.2635" />
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1292" to="1298" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Krajbich, I., Armel, C., &amp; Rangel, A. (2010). Visual fixations and the computation and comparison of value in simple choice. Nature Neuroscience, 13 (10), 1292-1298. https://doi.org/10.1038/nn.2635</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Quantitative models of attention and response processes in shape identification tasks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Laberge</surname></persName>
		</author>
		<idno type="DOI">10.1006/jmps.1994.1015</idno>
		<ptr target="https://doi.org/10.1006/jmps.1994.1015" />
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="198" to="243" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
	<note type="raw_reference">LaBerge, D. (1994). Quantitative models of attention and response processes in shape identification tasks. Journal of Mathematical Psychology, 38 (2), 198-243. https://doi.org/10.1006/jmps.1994.1015</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Model complexity in diffusion modeling: Benefits of making the model more parsimonious</title>
		<author>
			<persName><forename type="first">V</forename><surname>Lerche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Voss</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2016.01324</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2016.01324" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">1324</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Lerche, V., &amp; Voss, A. (2016). Model complexity in diffusion modeling: Benefits of making the model more parsimonious. Frontiers in Psychology, 7, 1324. https://doi.org/10.3389/fpsyg.2016.01324</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Retest reliability of the parameters of the ratcliff diffusion model</title>
		<author>
			<persName><forename type="first">V</forename><surname>Lerche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Voss</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00426-016-0770-5</idno>
		<ptr target="https://doi.org/10.1007/s00426-016-0770-5" />
	</analytic>
	<monogr>
		<title level="j">Psychological Research</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="629" to="652" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Lerche, V., &amp; Voss, A. (2017). Retest reliability of the parameters of the ratcliff diffusion model. Psychological Research, 81 (3), 629-652. https://doi.org/10.1007/s00426-016-0770-5</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Experimental validation of the diffusion model based on a slow response time paradigm</title>
		<author>
			<persName><forename type="first">V</forename><surname>Lerche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Voss</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00426-017-0945-8</idno>
		<ptr target="https://doi.org/10.1007/s00426-017-0945-8" />
	</analytic>
	<monogr>
		<title level="j">Psychological Research</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1194" to="1209" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Lerche, V., &amp; Voss, A. (2019). Experimental validation of the diffusion model based on a slow response time paradigm. Psychological Research, 83 (6), 1194-1209. https://doi.org/10.1007/s00426-017-0945-8</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">How many trials are required for parameter estimation in diffusion modeling? a comparison of different optimization criteria</title>
		<author>
			<persName><forename type="first">V</forename><surname>Lerche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nagler</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13428-016-0740-2</idno>
		<ptr target="https://doi.org/10.3758/s13428-016-0740-2" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="513" to="537" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Lerche, V., Voss, A., &amp; Nagler, M. (2017). How many trials are required for parameter estimation in diffusion modeling? a comparison of different optimization criteria. Behavior Research Methods, 49 (2), 513-537. https://doi.org/10.3758/s13428-016-0740-2</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A concordance correlation coefficient to evaluate reproducibility</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">I</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="255" to="268" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Lin, L. I. (1989). A concordance correlation coefficient to evaluate reproducibility. Biometrics, 45 (1), 255-268.</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Modeling perceptual confidence and the confidence forced-choice paradigm</title>
		<author>
			<persName><forename type="first">P</forename><surname>Mamassian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>De Gardelle</surname></persName>
		</author>
		<idno type="DOI">10.1037/rev0000312</idno>
		<ptr target="https://doi.org/10.1037/rev0000312" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="976" to="998" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Mamassian, P., &amp; de Gardelle, V. (2022). Modeling perceptual confidence and the confidence forced-choice paradigm. Psychological Review, 129 (5), 976-998. https://doi.org/10.1037/rev0000312</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A signal detection theoretic approach for estimating metacognitive sensitivity from confidence ratings</title>
		<author>
			<persName><forename type="first">B</forename><surname>Maniscalco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lau</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.concog.2011.09.021</idno>
		<ptr target="https://doi.org/10.1016/j.concog.2011.09.021" />
	</analytic>
	<monogr>
		<title level="j">Consciousness and cognition</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="422" to="430" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Maniscalco, B., &amp; Lau, H. (2012). A signal detection theoretic approach for estimating metacognitive sensitivity from confidence ratings. Consciousness and cognition, 21 (1), 422-430. https://doi.org/10.1016/j.concog.2011.09.021</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The signal processing architecture underlying subjective reports of sensory awareness</title>
		<author>
			<persName><forename type="first">B</forename><surname>Maniscalco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lau</surname></persName>
		</author>
		<idno type="DOI">10.1093/nc/niw002</idno>
		<ptr target="https://doi.org/10.1093/nc/niw002" />
	</analytic>
	<monogr>
		<title level="j">Neuroscience of consciousness</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Maniscalco, B., &amp; Lau, H. (2016). The signal processing architecture underlying subjective reports of sensory awareness. Neuroscience of consciousness, 2016 (1). https://doi.org/10.1093/nc/niw002</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Heuristic use of perceptual evidence leads to dissociation between performance and metacognitive sensitivity</title>
		<author>
			<persName><forename type="first">B</forename><surname>Maniscalco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A K</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lau</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13414-016-1059-x</idno>
		<ptr target="https://doi.org/10.3758/s13414-016-1059-x" />
	</analytic>
	<monogr>
		<title level="j">Attention, Perception, &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="923" to="937" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Maniscalco, B., Peters, M. A. K., &amp; Lau, H. (2016). Heuristic use of perceptual evidence leads to dissociation between performance and metacognitive sensitivity. Attention, Perception, &amp; Psychophysics, 78 (3), 923-937. https://doi.org/10.3758/s13414-016-1059-x</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">The drift diffusion model can account for the accuracy and reaction time of value-based choices under high and low time pressure</title>
		<author>
			<persName><forename type="first">M</forename><surname>Milosavljevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malmaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Huth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rangel</surname></persName>
		</author>
		<idno type="DOI">10.2139/ssrn.1901533</idno>
		<ptr target="https://doi.org/10.2139/ssrn.1901533" />
	</analytic>
	<monogr>
		<title level="j">SSRN Electronic Journal</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Milosavljevic, M., Malmaud, J., Huth, A., Koch, C., &amp; Rangel, A. (2010). The drift diffusion model can account for the accuracy and reaction time of value-based choices under high and low time pressure. SSRN Electronic Journal. https://doi.org/10.2139/ssrn.1901533</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Post choice information integration as a causal determinant of confidence: Novel data and a computational account</title>
		<author>
			<persName><forename type="first">R</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Teodorescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Usher</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cogpsych.2015.01.002</idno>
		<ptr target="https://doi.org/10.1016/j.cogpsych.2015.01.002" />
	</analytic>
	<monogr>
		<title level="j">Cognitive psychology</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="99" to="147" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Moran, R., Teodorescu, A. R., &amp; Usher, M. (2015). Post choice information integration as a causal determinant of confidence: Novel data and a computational account. Cognitive psychology, 78, 99-147. https://doi.org/10.1016/j.cogpsych.2015.01.002</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Decision confidence and uncertainty in diffusion models with partially correlated neuronal integrators</title>
		<author>
			<persName><forename type="first">R</forename><surname>Moreno-Bote</surname></persName>
		</author>
		<idno type="DOI">10.1162/neco.2010.12-08-930</idno>
		<ptr target="https://doi.org/10.1162/neco.2010.12-08-930" />
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Moreno-Bote, R. (2010). Decision confidence and uncertainty in diffusion models with partially correlated neuronal integrators. Neural computation, 22 (7). https://doi.org/10.1162/neco.2010.12-08-930</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Bayesfactor: Computation of bayes factors for common designs (version 0.9</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Morey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Rouder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jamil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Urbanek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Forner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ly</surname></persName>
		</author>
		<ptr target="https://cran.r-project.org/web/packages/BayesFactor" />
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="12" to="14" />
		</imprint>
	</monogr>
	<note type="raw_reference">Morey, R. D., Rouder, J. N., Jamil, T., Urbanek, S., Forner, K., &amp; Ly, A. (2024). Bayesfactor: Computation of bayes factors for common designs (version 0.9.12-4.7). https://cran.r-project.org/web/packages/BayesFactor</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">The importance of complexity in model selection</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Myung</surname></persName>
		</author>
		<idno type="DOI">10.1006/jmps.1999.1283</idno>
		<ptr target="https://doi.org/10.1006/jmps.1999.1283" />
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="190" to="204" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Myung, I. J. (2000). The importance of complexity in model selection. Journal of Mathematical Psychology, 44 (1), 190-204. https://doi.org/10.1006/jmps.1999.1283</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Fast and accurate calculations for first-passage times in wiener diffusion models</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Navarro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">G</forename><surname>Fuss</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jmp.2009.02.003</idno>
		<ptr target="https://doi.org/10.1016/j.jmp.2009.02.003" />
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="222" to="230" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Navarro, D. J., &amp; Fuss, I. G. (2009). Fast and accurate calculations for first-passage times in wiener diffusion models. Journal of Mathematical Psychology, 53 (4), 222-230. https://doi.org/10.1016/j.jmp.2009.02.003</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A comparison of current measures of the accuracy of feeling-of-knowing predictions</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">O</forename><surname>Nelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological bulletin</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="109" to="133" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Nelson, T. O. (1984). A comparison of current measures of the accuracy of feeling-of-knowing predictions. Psychological bulletin, 95 (1), 109-133.</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Metacognitive adaptation revealed in serial dependence of visual confidence judgments</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C H</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">H F</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M W</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Or</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-F</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L F</forename></persName>
		</author>
		<idno type="DOI">10.1167/jov.21.9.2487</idno>
		<ptr target="https://doi.org/10.1167/jov.21.9.2487" />
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">2487</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ng, L. C. H., Law, F. H. F., Lam, A. M. W., Or, C. C.-F., &amp; Lee, A. L. F. (2021). Metacognitive adaptation revealed in serial dependence of visual confidence judgments. Journal of Vision, 21 (9), 2487. https://doi.org/10.1167/jov.21.9.2487</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Internal noise measures in coarse and fine motion direction discrimination tasks and the correlation with autism traits</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Orchard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Dakin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J A</forename><surname>Van Boxtel</surname></persName>
		</author>
		<idno type="DOI">10.1167/jov.22.10.19</idno>
		<ptr target="https://doi.org/10.1167/jov.22.10.19" />
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">19</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Orchard, E. R., Dakin, S. C., &amp; van Boxtel, J. J. A. (2022). Internal noise measures in coarse and fine motion direction discrimination tasks and the correlation with autism traits. Journal of Vision, 22 (10), 19. https://doi.org/10.1167/jov.22.10.19</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">The importance of falsification in computational cognitive modeling</title>
		<author>
			<persName><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Wyart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Koechlin</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2017.03.011</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2017.03.011" />
	</analytic>
	<monogr>
		<title level="j">Trends in cognitive sciences</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="425" to="433" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Palminteri, S., Wyart, V., &amp; Koechlin, E. (2017). The importance of falsification in computational cognitive modeling. Trends in cognitive sciences, 21 (6), 425-433. https://doi.org/10.1016/j.tics.2017.03.011</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Millisecond precision psychological research in a world of commodity computers: New hardware, new problems?</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Plant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Turner</surname></persName>
		</author>
		<idno type="DOI">10.3758/BRM.41.3.598</idno>
		<ptr target="https://doi.org/10.3758/BRM.41.3.598" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="598" to="614" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Plant, R. R., &amp; Turner, G. (2009). Millisecond precision psychological research in a world of commodity computers: New hardware, new problems? Behavior Research Methods, 41 (3), 598-614. https://doi.org/10.3758/BRM.41.3.598</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Two-stage dynamic signal detection: A theory of choice, decision time, and confidence</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Pleskac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Busemeyer</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0019737</idno>
		<ptr target="https://doi.org/10.1037/a0019737" />
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Pleskac, T. J., &amp; Busemeyer, J. (2010). Two-stage dynamic signal detection: A theory of choice, decision time, and confidence. Psychological review, 117 (3). https://doi.org/10.1037/a0019737</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Confidence and certainty: Distinct probabilistic quantities for different goals</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pouget</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Drugowitsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kepecs</surname></persName>
		</author>
		<idno type="DOI">10.1038/nn.4240</idno>
		<ptr target="https://doi.org/10.1038/nn.4240" />
	</analytic>
	<monogr>
		<title level="j">Nature neuroscience</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="366" to="374" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Pouget, A., Drugowitsch, J., &amp; Kepecs, A. (2016). Confidence and certainty: Distinct probabilistic quantities for different goals. Nature neuroscience, 19 (3), 366-374. https://doi.org/10.1038/nn.4240</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">The confidence database</title>
		<author>
			<persName><forename type="first">D</forename><surname>Rahnev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Desender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L F</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Adler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Aguilar-Lleyda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Akdoğan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Arbuzova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">Y</forename><surname>Atlas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Balcı</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Bang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Bègue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Birney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Brady</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Calder-Travis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chetverikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Davranche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Denison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Dildine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Zylberberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename></persName>
		</author>
		<idno type="DOI">10.1038/s41562-019-0813-1</idno>
		<ptr target="https://doi.org/10.1038/s41562-019-0813-1" />
	</analytic>
	<monogr>
		<title level="j">Nature human behaviour</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="317" to="325" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Rahnev, D., Desender, K., Lee, A. L. F., Adler, W. T., Aguilar-Lleyda, D., Akdoğan, B., Arbuzova, P., Atlas, L. Y., Balcı, F., Bang, J. W., Bègue, I., Birney, D. P., Brady, T. F., Calder-Travis, J., Chetverikov, A., Clark, T. K., Davranche, K., Denison, R. N., Dildine, T. C., . . . Zylberberg, A. (2020). The confidence database. Nature human behaviour, 4 (3), 317-325. https://doi.org/10.1038/s41562-019-0813-1</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A theory of memory retrieval</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-295X.85.2.59</idno>
		<ptr target="https://doi.org/10.1037/0033-295X.85.2.59" />
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="59" to="108" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ratcliff, R. (1978). A theory of memory retrieval. Psychological review, 85 (2), 59-108. https://doi.org/10.1037/0033-295X.85.2.59</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A diffusion model account of the lexical decision task</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mckoon</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-295X.111.1.159</idno>
		<ptr target="https://doi.org/10.1037/0033-295X.111.1.159" />
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="159" to="182" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ratcliff, R., Gomez, P., &amp; McKoon, G. (2004). A diffusion model account of the lexical decision task. Psychological review, 111 (1), 159-182. https://doi.org/10.1037/0033-295X.111.1.159</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Modeling response times for two-choice decisions</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Rouder</surname></persName>
		</author>
		<idno type="DOI">10.1111/1467-9280.00067</idno>
		<ptr target="https://doi.org/10.1111/1467-9280.00067" />
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="347" to="356" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ratcliff, R., &amp; Rouder, J. N. (1998). Modeling response times for two-choice decisions. Psychological Science, 9 (5), 347-356. https://doi.org/10.1111/1467-9280.00067</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">A comparison of sequential sampling models for two-choice reaction time</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-295X.111.2.333</idno>
		<ptr target="https://doi.org/10.1037/0033-295X.111.2.333" />
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="333" to="367" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ratcliff, R., &amp; Smith, P. L. (2004). A comparison of sequential sampling models for two-choice reaction time. Psychological review, 111 (2), 333-367. https://doi.org/10.1037/0033-295X.111.2.333</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Modeling confidence and response time in recognition memory</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Starns</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0014086</idno>
		<ptr target="https://doi.org/10.1037/a0014086" />
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="59" to="83" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ratcliff, R., &amp; Starns, J. J. (2009). Modeling confidence and response time in recognition memory. Psychological review, 116 (1), 59-83. https://doi.org/10.1037/a0014086</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Modeling confidence judgments, response times, and multiple choices in decision making: Recognition memory and motion discrimination</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Starns</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0033152</idno>
		<ptr target="https://doi.org/10.1037/a0033152" />
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="697" to="719" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ratcliff, R., &amp; Starns, J. J. (2013). Modeling confidence judgments, response times, and multiple choices in decision making: Recognition memory and motion discrimination. Psychological review, 120 (3), 697-719. https://doi.org/10.1037/a0033152</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Estimating parameters of the diffusion model: Approaches to dealing with contaminant reaction times and parameter variability</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tuerlinckx</surname></persName>
		</author>
		<idno type="DOI">10.3758/bf03196302</idno>
		<ptr target="https://doi.org/10.3758/bf03196302" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic bulletin &amp; review</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="438" to="481" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ratcliff, R., &amp; Tuerlinckx, F. (2002). Estimating parameters of the diffusion model: Approaches to dealing with contaminant reaction times and parameter variability. Psychonomic bulletin &amp; review, 9 (3), 438-481. https://doi.org/10.3758/bf03196302</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Modeling 2-alternative forced-choice tasks: Accounting for both magnitude and difference effects</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Voskuilen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Teodorescu</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cogpsych.2018.02.002</idno>
		<ptr target="https://doi.org/10.1016/j.cogpsych.2018.02.002" />
	</analytic>
	<monogr>
		<title level="j">Cognitive psychology</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ratcliff, R., Voskuilen, C., &amp; Teodorescu, A. (2018). Modeling 2-alternative forced-choice tasks: Accounting for both magnitude and difference effects. Cognitive psychology, 103, 1-22. https://doi.org/10.1016/j.cogpsych.2018.02.002</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Confidence in masked orientation judgments is informed by both evidence and visibility</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rausch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hellmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zehetleitner</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13414-017-1431-5</idno>
		<ptr target="https://doi.org/10.3758/s13414-017-1431-5" />
	</analytic>
	<monogr>
		<title level="j">Attention, Perception, &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="134" to="154" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Rausch, M., Hellmann, S., &amp; Zehetleitner, M. (2018). Confidence in masked orientation judgments is informed by both evidence and visibility. Attention, Perception, &amp; Psychophysics, 80 (1), 134-154. https://doi.org/10.3758/s13414-017-1431-5</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Measures of metacognitive efficiency across cognitive models of decision confidence</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rausch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hellmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zehetleitner</surname></persName>
		</author>
		<idno type="DOI">10.1037/met0000634</idno>
		<ptr target="https://doi.org/10.1037/met0000634" />
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Rausch, M., Hellmann, S., &amp; Zehetleitner, M. (2023). Measures of metacognitive efficiency across cognitive models of decision confidence. Psychological Methods. https://doi.org/10.1037/met0000634</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Statconfr: An r package for static models of decision confidence and metacognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rausch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Meyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hellmann</surname></persName>
		</author>
		<idno type="DOI">10.21105/joss.06966</idno>
		<ptr target="https://doi.org/10.21105/joss.06966" />
	</analytic>
	<monogr>
		<title level="j">Journal of Open Source Software</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">106</biblScope>
			<biblScope unit="page">6966</biblScope>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Rausch, M., Meyen, S., &amp; Hellmann, S. (2025). Statconfr: An r package for static models of decision confidence and metacognition. Journal of Open Source Software, 10 (106), 6966. https://doi.org/10.21105/joss.06966</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">The folded x-pattern is not necessarily a statistical signature of decision confidence</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rausch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zehetleitner</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pcbi.1007456</idno>
		<ptr target="https://doi.org/10.1371/journal.pcbi.1007456" />
	</analytic>
	<monogr>
		<title level="j">PLoS computational biology</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">1007456</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Rausch, M., &amp; Zehetleitner, M. (2019). The folded x-pattern is not necessarily a statistical signature of decision confidence. PLoS computational biology, 15 (10), Article e1007456. https://doi.org/10.1371/journal.pcbi.1007456</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Cognitive modelling reveals distinct electrophysiological markers of decision confidence and error monitoring</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rausch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zehetleitner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Steinhauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Maier</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2020.116963</idno>
		<ptr target="https://doi.org/10.1016/j.neuroimage.2020.116963" />
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">218</biblScope>
			<biblScope unit="page">116963</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Rausch, M., Zehetleitner, M., Steinhauser, M., &amp; Maier, M. E. (2020). Cognitive modelling reveals distinct electrophysiological markers of decision confidence and error monitoring. NeuroImage, 218, Article 116963. https://doi.org/10.1016/j.neuroimage.2020.116963</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Correlated racing evidence accumulator models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Kvam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Osth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Heathcote</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jmp.2020.102331</idno>
		<ptr target="https://doi.org/10.1016/j.jmp.2020.102331" />
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page">102331</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Reynolds, A., Kvam, P. D., Osth, A. F., &amp; Heathcote, A. (2020). Correlated racing evidence accumulator models. Journal of Mathematical Psychology, 96, 102331. https://doi.org/10.1016/j.jmp.2020.102331</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Bayesian model selection for group studies -revisited</title>
		<author>
			<persName><forename type="first">L</forename><surname>Rigoux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Stephan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Friston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Daunizeau</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2013.08.065</idno>
		<ptr target="https://doi.org/10.1016/j.neuroimage.2013.08.065" />
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="971" to="985" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Rigoux, L., Stephan, K. E., Friston, K. J., &amp; Daunizeau, J. (2014). Bayesian model selection for group studies -revisited. NeuroImage, 84, 971-985. https://doi.org/10.1016/j.neuroimage.2013.08.065</note>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">The replication database: Documenting the replicability of psychological science</title>
		<author>
			<persName><forename type="first">L</forename><surname>Röseler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Doetsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Klett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Seida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schütz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Aczel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Adelina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Agostini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Alarie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Albayarak-Aydemir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aldoh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Al-Hoorie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Azevedo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Barth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Beitner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Brick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Brohmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename></persName>
		</author>
		<idno type="DOI">10.31222/osf.io/me2ub</idno>
		<ptr target="https://doi.org/10.31222/osf.io/me2ub" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Röseler, L., Kaiser, L., Doetsch, C. A., Klett, N., Seida, C., Schütz, A., Aczel, B., Adelina, N., Agostini, V., Alarie, S., Albayarak-Aydemir, N., Aldoh, A., Al-Hoorie, A. H., Azevedo, F., Baker, B. J., Barth, C. L., Beitner, J., Brick, C., Brohmer, H., . . . Zhang, Y. (2024). The replication database: Documenting the replicability of psychological science. https://doi.org/10.31222/osf.io/me2ub</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Estimating the dimension of a model</title>
		<author>
			<persName><forename type="first">G</forename><surname>Schwarz</surname></persName>
		</author>
		<idno type="DOI">10.1214/aos/1176344136</idno>
		<ptr target="https://doi.org/10.1214/aos/1176344136" />
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="461" to="464" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Schwarz, G. (1978). Estimating the dimension of a model. The Annals of Statistics, 6 (2), 461-464. https://doi.org/10.1214/aos/1176344136</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Online psychophysics: Reaction time effects in cognitive experiments</title>
		<author>
			<persName><forename type="first">K</forename><surname>Semmelmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Weigelt</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13428-016-0783-4</idno>
		<ptr target="https://doi.org/10.3758/s13428-016-0783-4" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1241" to="1260" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Semmelmann, K., &amp; Weigelt, S. (2017). Online psychophysics: Reaction time effects in cognitive experiments. Behavior Research Methods, 49 (4), 1241-1260. https://doi.org/10.3758/s13428-016-0783-4</note>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">The nature of metacognitive inefficiency in perceptual decision making</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shekhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rahnev</surname></persName>
		</author>
		<idno type="DOI">10.1037/rev0000249</idno>
		<ptr target="https://doi.org/10.1037/rev0000249" />
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="45" to="70" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Shekhar, M., &amp; Rahnev, D. (2021). The nature of metacognitive inefficiency in perceptual decision making. Psychological review, 128 (1), 45-70. https://doi.org/10.1037/rev0000249</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">How do humans give confidence? a comprehensive comparison of process models of perceptual metacognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shekhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rahnev</surname></persName>
		</author>
		<idno type="DOI">10.1037/xge0001524</idno>
		<ptr target="https://doi.org/10.1037/xge0001524" />
	</analytic>
	<monogr>
		<title level="j">Journal of experimental psychology. General</title>
		<imprint>
			<biblScope unit="volume">153</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="656" to="688" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Shekhar, M., &amp; Rahnev, D. (2024). How do humans give confidence? a comprehensive comparison of process models of perceptual metacognition. Journal of experimental psychology. General, 153 (3), 656-688. https://doi.org/10.1037/xge0001524</note>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Rtdists: Response time distributions</title>
		<author>
			<persName><forename type="first">H</forename><surname>Singmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Heathcote</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Terry</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Singmann, H., Brown, S. D., Gretton, M., Heathcote, A., Voss, A., Voss, J., &amp; Terry, A. (2020). Rtdists: Response time distributions.</note>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Stochastic dynamic models of response time and accuracy: A foundational primer</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.1006/jmps.1999.1260</idno>
		<ptr target="https://doi.org/10.1006/jmps.1999.1260" />
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="408" to="463" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Smith, P. L. (2000). Stochastic dynamic models of response time and accuracy: A foundational primer. Journal of Mathematical Psychology, 44 (3), 408-463. https://doi.org/10.1006/jmps.1999.1260</note>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Bayesian model selection for group studies</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Stephan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">D</forename><surname>Penny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Daunizeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Friston</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2009.03.025</idno>
		<ptr target="https://doi.org/10.1016/j.neuroimage.2009.03.025" />
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1004" to="1017" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Stephan, K. E., Penny, W. D., Daunizeau, J., Moran, R. J., &amp; Friston, K. J. (2009). Bayesian model selection for group studies. NeuroImage, 46 (4), 1004-1017. https://doi.org/10.1016/j.neuroimage.2009.03.025</note>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Emc2: An r package for cognitive models of choice</title>
		<author>
			<persName><forename type="first">N</forename><surname>Stevenson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Donzallaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Innes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Forstmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Matzke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Heathcote</surname></persName>
		</author>
		<idno type="DOI">10.31234/osf.io/2e4dq</idno>
		<ptr target="https://doi.org/10.31234/osf.io/2e4dq" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Stevenson, N., Donzallaz, M. C., Innes, R. J., Forstmann, B., Matzke, D., &amp; Heathcote, A. (2024). Emc2: An r package for cognitive models of choice. https://doi.org/10.31234/osf.io/2e4dq</note>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Optimal policy for value-based decision-making</title>
		<author>
			<persName><forename type="first">S</forename><surname>Tajima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Drugowitsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pouget</surname></persName>
		</author>
		<idno type="DOI">10.1038/ncomms12400</idno>
		<ptr target="https://doi.org/10.1038/ncomms12400" />
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">12400</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Tajima, S., Drugowitsch, J., &amp; Pouget, A. (2016). Optimal policy for value-based decision-making. Nature Communications, 7 (1), Article 12400. https://doi.org/10.1038/ncomms12400</note>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Absolutely relative or relatively absolute: Violations of value invariance in human decision making</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Teodorescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Usher</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13423-015-0858-8</idno>
		<ptr target="https://doi.org/10.3758/s13423-015-0858-8" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="22" to="38" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Teodorescu, A. R., Moran, R., &amp; Usher, M. (2016). Absolutely relative or relatively absolute: Violations of value invariance in human decision making. Psychonomic Bulletin &amp; Review, 23 (1), 22-38. https://doi.org/10.3758/s13423-015-0858-8</note>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Disentangling decision models: From independence to competition</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Teodorescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Usher</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0030776</idno>
		<ptr target="https://doi.org/10.1037/a0030776" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Teodorescu, A. R., &amp; Usher, M. (2013). Disentangling decision models: From independence to competition. Psychological Review, 120 (1), 1-38. https://doi.org/10.1037/a0030776</note>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">The time course of perceptual choice: The leaky, competing accumulator model</title>
		<author>
			<persName><forename type="first">M</forename><surname>Usher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Mcclelland</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-295x.108.3.550</idno>
		<ptr target="https://doi.org/10.1037/0033-295x.108.3.550" />
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="550" to="592" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Usher, M., &amp; McClelland, J. L. (2001). The time course of perceptual choice: The leaky, competing accumulator model. Psychological review, 108 (3), 550-592. https://doi.org/10.1037/0033-295x.108.3.550</note>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">A common mechanism underlies changes of mind about decisions and confidence</title>
		<author>
			<persName><forename type="first">R</forename><surname>Van Den Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Anandalingam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zylberberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kiani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Shadlen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Wolpert</surname></persName>
		</author>
		<idno type="DOI">10.7554/eLife.12192</idno>
		<ptr target="https://doi.org/10.7554/eLife.12192" />
	</analytic>
	<monogr>
		<title level="j">eLife</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>Article e12192</note>
	<note type="raw_reference">van den Berg, R., Anandalingam, K., Zylberberg, A., Kiani, R., Shadlen, M. N., &amp; Wolpert, D. M. (2016). A common mechanism underlies changes of mind about decisions and confidence. eLife, 5, Article e12192. https://doi.org/10.7554/eLife.12192</note>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Experimental paradigms emphasising state or process limitations: Ii effects on confidence</title>
		<author>
			<persName><forename type="first">D</forename><surname>Vickers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Burt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brown</surname></persName>
		</author>
		<idno type="DOI">10.1016/0001-6918(85)90018-6</idno>
		<ptr target="https://doi.org/10.1016/0001-6918(85)90018-6" />
	</analytic>
	<monogr>
		<title level="j">Acta Psychologica</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="163" to="193" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Vickers, D., Smith, P., Burt, J., &amp; Brown, M. (1985). Experimental paradigms emphasising state or process limitations: Ii effects on confidence. Acta Psychologica, 59 (2), 163-193. https://doi.org/10.1016/0001-6918(85)90018-6</note>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Diffusion models in experimental psychology: A practical introduction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nagler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Lerche</surname></persName>
		</author>
		<idno type="DOI">10.1027/1618-3169/a000218</idno>
		<ptr target="https://doi.org/10.1027/1618-3169/a000218" />
	</analytic>
	<monogr>
		<title level="j">Experimental psychology</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Voss, A., Nagler, M., &amp; Lerche, V. (2013). Diffusion models in experimental psychology: A practical introduction. Experimental psychology, 60 (6). https://doi.org/10.1027/1618-3169/a000218</note>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Interpreting the parameters of the diffusion model: An empirical validation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Rothermund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Voss</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03196893</idno>
		<ptr target="https://doi.org/10.3758/BF03196893" />
	</analytic>
	<monogr>
		<title level="j">Memory &amp; Cognition</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1206" to="1220" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Voss, A., Rothermund, K., &amp; Voss, J. (2004). Interpreting the parameters of the diffusion model: An empirical validation. Memory &amp; Cognition, 32 (7), 1206-1220. https://doi.org/10.3758/BF03196893</note>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Extending jags: A tutorial on adding custom distributions to jags (with a diffusion model example)</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wabersich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vandekerckhove</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13428-013-0369-3</idno>
		<ptr target="https://doi.org/10.3758/s13428-013-0369-3" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="15" to="28" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Wabersich, D., &amp; Vandekerckhove, J. (2014a). Extending jags: A tutorial on adding custom distributions to jags (with a diffusion model example). Behavior Research Methods, 46 (1), 15-28. https://doi.org/10.3758/s13428-013-0369-3</note>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">The rwiener package: An r package providing distribution functions for the wiener diffusion model</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wabersich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vandekerckhove</surname></persName>
		</author>
		<idno type="DOI">10.32614/RJ-2014-005</idno>
		<ptr target="https://doi.org/10.32614/RJ-2014-005" />
	</analytic>
	<monogr>
		<title level="j">The R Journal</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">49</biblScope>
			<date type="published" when="2014">2014b</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Wabersich, D., &amp; Vandekerckhove, J. (2014b). The rwiener package: An r package providing distribution functions for the wiener diffusion model. The R Journal, 6 (1), 49. https://doi.org/10.32614/RJ-2014-005</note>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">An agenda for purely confirmatory research</title>
		<author>
			<persName><forename type="first">E.-J</forename><surname>Wagenmakers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wetzels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Borsboom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">L J</forename><surname>Van Der Maas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Kievit</surname></persName>
		</author>
		<idno type="DOI">10.1177/1745691612463078</idno>
		<ptr target="https://doi.org/10.1177/1745691612463078" />
	</analytic>
	<monogr>
		<title level="j">Perspectives on psychological science : a journal of the Association for Psychological Science</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="632" to="638" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Wagenmakers, E.-J., Wetzels, R., Borsboom, D., van der Maas, H. L. J., &amp; Kievit, R. A. (2012). An agenda for purely confirmatory research. Perspectives on psychological science : a journal of the Association for Psychological Science, 7 (6), 632-638. https://doi.org/10.1177/1745691612463078</note>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Hddm: Hierarchical bayesian estimation of the drift-diffusion model in python</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">V</forename><surname>Wiecki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Frank</surname></persName>
		</author>
		<idno type="DOI">10.3389/fninf.2013.00014</idno>
		<ptr target="https://doi.org/10.3389/fninf.2013.00014" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in neuroinformatics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">14</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Wiecki, T. V., Sofer, I., &amp; Frank, M. J. (2013). Hddm: Hierarchical bayesian estimation of the drift-diffusion model in python. Frontiers in neuroinformatics, 7, 14. https://doi.org/10.3389/fninf.2013.00014</note>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Confidence in forced-choice recognition: What underlies the ratings? Journal of experimental psychology</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zawadzka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Higham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hanczakowski</surname></persName>
		</author>
		<idno type="DOI">10.1037/xlm0000321</idno>
		<ptr target="https://doi.org/10.1037/xlm0000321" />
	</analytic>
	<monogr>
		<title level="j">Learning, memory, and cognition</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="552" to="564" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Zawadzka, K., Higham, P. A., &amp; Hanczakowski, M. (2017). Confidence in forced-choice recognition: What underlies the ratings? Journal of experimental psychology. Learning, memory, and cognition, 43 (4), 552-564. https://doi.org/10.1037/xlm0000321</note>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">The construction of confidence in a perceptual decision</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zylberberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Barttfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sigman</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnint.2012.00079</idno>
		<ptr target="https://doi.org/10.3389/fnint.2012.00079" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in integrative neuroscience</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Zylberberg, A., Barttfeld, P., &amp; Sigman, M. (2012). The construction of confidence in a perceptual decision. Frontiers in integrative neuroscience, 6, Article 79. https://doi.org/10.3389/fnint.2012.00079</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
